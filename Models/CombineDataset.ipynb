{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Import Libarys"
      ],
      "metadata": {
        "id": "DsMUlLM337tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "!pip install torch\n",
        "!pip install pytorch-tabnet\n",
        "!pip install sdv # for CTGAN\n"
      ],
      "metadata": {
        "id": "YWhsVnb5Nddo",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c4c0e4-0e41-4ca1-c6f2-038c98330a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.3)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n",
            "Collecting sdv\n",
            "  Downloading sdv-1.29.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting boto3<2.0.0,>=1.28 (from sdv)\n",
            "  Downloading boto3-1.42.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting botocore<2.0.0,>=1.31 (from sdv)\n",
            "  Downloading botocore-1.41.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from sdv) (3.1.2)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from sdv) (0.21)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from sdv) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.12/dist-packages (from sdv) (4.67.1)\n",
            "Collecting copulas>=0.12.1 (from sdv)\n",
            "  Downloading copulas-0.12.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting ctgan>=0.11.0 (from sdv)\n",
            "  Downloading ctgan-0.11.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting deepecho>=0.7.0 (from sdv)\n",
            "  Downloading deepecho-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rdt>=1.18.2 (from sdv)\n",
            "  Downloading rdt-1.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sdmetrics>=0.21.0 (from sdv)\n",
            "  Downloading sdmetrics-0.24.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.12/dist-packages (from sdv) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from sdv) (6.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.5.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.12/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from copulas>=0.12.1->sdv) (1.16.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from ctgan>=0.11.0->sdv) (2.9.0+cu126)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.1->sdv) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.1->sdv) (2025.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from rdt>=1.18.2->sdv) (1.6.1)\n",
            "Collecting Faker!=37.11.0,>=17 (from rdt>=1.18.2->sdv)\n",
            "  Downloading faker-38.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->rdt>=1.18.2->sdv) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.1->rdt>=1.18.2->sdv) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->ctgan>=0.11.0->sdv) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->ctgan>=0.11.0->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->ctgan>=0.11.0->sdv) (3.0.3)\n",
            "Downloading sdv-1.29.1-py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.0/197.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.42.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.41.6-py3-none-any.whl (14.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading copulas-0.12.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctgan-0.11.1-py3-none-any.whl (25 kB)\n",
            "Downloading deepecho-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading rdt-1.18.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sdmetrics-0.24.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.3/198.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-38.2.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, Faker, botocore, s3transfer, rdt, copulas, sdmetrics, deepecho, ctgan, boto3, sdv\n",
            "Successfully installed Faker-38.2.0 boto3-1.42.0 botocore-1.41.6 copulas-0.12.3 ctgan-0.11.1 deepecho-0.7.0 jmespath-1.0.1 rdt-1.18.2 s3transfer-0.16.0 sdmetrics-0.24.0 sdv-1.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report ,f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import kagglehub\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold , train_test_split\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Input ,Conv2D, MaxPooling2D,Conv1D, MaxPooling1D, Flatten, Dense, Dropout,LSTM\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata"
      ],
      "metadata": {
        "id": "UHDZNim21fjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call The Merged DataSet"
      ],
      "metadata": {
        "id": "_kb8OfTp5ycj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/merged_fire_data_cleaned.csv\")\n",
        "#df = pd.read_csv(\"merged_fire_data .csv\")\n",
        "\n",
        "print(\"Class distribution:\\n\", df[\"Classes\"].value_counts())\n",
        "print(\"Combined dataset shape:\", df.shape)\n"
      ],
      "metadata": {
        "id": "Amo4_Ons2k1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1e39d7-5dfa-47ea-dc8e-016c6ed6e5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            " Classes\n",
            "0    646\n",
            "1    210\n",
            "Name: count, dtype: int64\n",
            "Combined dataset shape: (856, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features & target\n",
        "X = df.drop(\"Classes\", axis=1)\n",
        "y = df[\"Classes\"]\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "NaGnulu6BQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning"
      ],
      "metadata": {
        "id": "WM7TllwDzBO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "bHRBGt5VLPF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "# Define a grid of hyperparameters\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 5],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Display the best hyperparameter combination found during the search\n",
        "print(\"Best params:\", grid_rf.best_params_)\n",
        "\n",
        "# Display the best cross-validation accuracy\n",
        "print(\"Best CV Accuracy:\", grid_rf.best_score_)\n",
        "\n",
        "# Explicit Cross-Validation with best model\n",
        "best_rf = grid_rf.best_estimator_\n",
        "cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "f1_fire = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-gLoD78Cfyk",
        "outputId": "a5d19ef7-415f-4dc5-ed91-aa697809852c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best CV Accuracy: 0.9093173035637612\n",
            "CV Scores: [0.90510949 0.9270073  0.91970803 0.91240876 0.88235294]\n",
            "Mean CV: 0.9093173035637612\n",
            "Test Accuracy: 0.9186046511627907\n",
            "Overall F1 Score: 0.9125\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       130\n",
            "           1       1.00      0.67      0.80        42\n",
            "\n",
            "    accuracy                           0.92       172\n",
            "   macro avg       0.95      0.83      0.87       172\n",
            "weighted avg       0.93      0.92      0.91       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features:\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "RfgqDo0pH9al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression\n"
      ],
      "metadata": {
        "id": "MITDxwjaLWPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid = {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l2\"]}\n",
        "grid_log = GridSearchCV(log_reg, param_grid, cv=cv, scoring=\"accuracy\")\n",
        "grid_log.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best params:\", grid_log.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_log.best_score_)\n",
        "\n",
        "# Explicit Cross-Validation with best model\n",
        "best_log = grid_log.best_estimator_\n",
        "cv_scores = cross_val_score(best_log, X_train_scaled, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_log = best_log.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "\n",
        "f1_fire = f1_score(y_test, y_pred_log, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9QwX_bRIJ78",
        "outputId": "e5a04c58-5309-4bd4-9d0f-da2c3e2e402f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 10, 'penalty': 'l2'}\n",
            "Best CV Accuracy: 0.8932696436238728\n",
            "CV Scores: [0.88321168 0.89051095 0.90510949 0.90510949 0.88235294]\n",
            "Mean CV: 0.8932589094031773\n",
            "Test Accuracy: 0.9069767441860465\n",
            "Overall F1 Score: 0.9001\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94       130\n",
            "           1       0.96      0.64      0.77        42\n",
            "\n",
            "    accuracy                           0.91       172\n",
            "   macro avg       0.93      0.82      0.86       172\n",
            "weighted avg       0.91      0.91      0.90       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machine"
      ],
      "metadata": {
        "id": "icdPngS2WMuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Grid Search\n",
        "param_grid = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"kernel\": [\"linear\", \"rbf\"],\n",
        "    \"gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "grid_svm = GridSearchCV(svm, param_grid, cv=5, scoring=\"accuracy\")\n",
        "grid_svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best params:\", grid_svm.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_svm.best_score_)\n",
        "\n",
        "# Explicit Cross-Validation with best model\n",
        "best_svm = grid_svm.best_estimator_\n",
        "cv_scores = cross_val_score(best_svm, X_train_scaled, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_svm = best_svm.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "f1_fire = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZeqepWIIovi",
        "outputId": "52137e43-eb61-40c5-cca9-06a9f3c4574c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best CV Accuracy: 0.8874087591240876\n",
            "CV Scores: [0.88321168 0.90510949 0.89051095 0.88321168 0.875     ]\n",
            "Mean CV: 0.8874087591240876\n",
            "Test Accuracy: 0.8953488372093024\n",
            "Overall F1 Score: 0.8876\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       130\n",
            "           1       0.93      0.62      0.74        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.91      0.80      0.84       172\n",
            "weighted avg       0.90      0.90      0.89       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels (Convert categorical labels to numbers)\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)\n",
        "scaler = StandardScaler()\n",
        "X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "XeS9pvjDwS7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "TfxeL4aDWngW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgb = XGBClassifier(\n",
        "    random_state=42,\n",
        "    eval_metric=\"mlogloss\"\n",
        ")\n",
        "\n",
        "# Grid Search\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "grid_xgb = GridSearchCV(xgb, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_xgb.fit(X_train, y_train_enc)\n",
        "\n",
        "print(\"Best params:\", grid_xgb.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_xgb.best_score_)\n",
        "\n",
        "# Explicit Cross-Validation with best model\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "cv_scores = cross_val_score(best_xgb, X_train, y_train_enc, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_enc, y_pred_xgb))\n",
        "f1_fire = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=[\"not fire\", \"fire\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wZQoNqCJrfL",
        "outputId": "583b4398-5701-4235-e35f-cac84ce440be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best CV Accuracy: 0.9385787891799054\n",
            "CV Scores: [0.94160584 0.95620438 0.9270073  0.94160584 0.92647059]\n",
            "Mean CV: 0.9385787891799054\n",
            "Test Accuracy: 0.9651162790697675\n",
            "Overall F1 Score: 0.9651\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.98      0.98      0.98       130\n",
            "        fire       0.93      0.93      0.93        42\n",
            "\n",
            "    accuracy                           0.97       172\n",
            "   macro avg       0.95      0.95      0.95       172\n",
            "weighted avg       0.97      0.97      0.97       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "FIGi8aaBnZDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\" Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_cat = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", round(accuracy_score(y_test, y_pred_cat), 4))\n",
        "f1_fire = f1_score(y_test, y_pred_cat, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffwaL-Y3KVds",
        "outputId": "2932bde2-905e-4b36-d25b-9e5817a32144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            " Best Parameters: {'depth': 4, 'iterations': 400, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
            "\n",
            "Accuracy: 0.9535\n",
            " Overall F1 Score: 0.9531\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       130\n",
            "           1       0.93      0.88      0.90        42\n",
            "\n",
            "    accuracy                           0.95       172\n",
            "   macro avg       0.94      0.93      0.94       172\n",
            "weighted avg       0.95      0.95      0.95       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensamble Learning"
      ],
      "metadata": {
        "id": "91iwsKc0w0JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=3,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(**grid_svm.best_params_, probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# XGBoost doesn’t need scaling\n",
        "xgb_model = XGBClassifier(**grid_xgb.best_params_, random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "# Create the VotingClassifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catBoost', catboost_model),\n",
        "        ('svm', svm_pipeline),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting to benefit from predicted probabilities\n",
        ")\n",
        "\n",
        "# Fit the ensemble\n",
        "voting_clf.fit(X_train, y_train_enc)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_ensemble = voting_clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Ensemble Test Accuracy:\", accuracy_score(y_test_enc, y_pred_ensemble))\n",
        "f1_fire = f1_score(y_test_enc, y_pred_ensemble, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "print(\"\\nEnsemble Classification Report:\\n\", classification_report(y_test, y_pred_ensemble, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PLKhBTdv9E6",
        "outputId": "ab48b26c-427b-4bcb-fa6b-2f0da53e9446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.9593023255813954\n",
            "Overall F1 Score: 0.9591\n",
            "\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.97      0.98      0.97       130\n",
            "        fire       0.93      0.90      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.95      0.94      0.94       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking Classifier\n"
      ],
      "metadata": {
        "id": "bEilv8El4bi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest + GridSearch\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {\"n_estimators\": [100, 200], \"max_depth\": [None, 10, 20]}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "print(\"Best RF Params:\", rf_grid.best_params_)\n",
        "\n",
        "# XGBoost + GridSearch + Scaling\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "xgb_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", xgb)])\n",
        "xgb_params = {\"clf__n_estimators\": [100, 200], \"clf__max_depth\": [3, 5, 7], \"clf__learning_rate\": [0.01, 0.1]}\n",
        "xgb_grid = GridSearchCV(xgb_pipe, xgb_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "print(\"Best XGB Params:\", xgb_grid.best_params_)\n",
        "\n",
        "# CatBoost + GridSearch\n",
        "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "cat_params = {\"iterations\": [200, 500], \"depth\": [4, 6, 8], \"learning_rate\": [0.01, 0.1]}\n",
        "cat_grid = GridSearchCV(cat, cat_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "cat_grid.fit(X_train, y_train)\n",
        "print(\"Best Cat Params:\", cat_grid.best_params_)\n",
        "\n",
        "# Stacking Classifier\n",
        "estimators = [\n",
        "    (\"rf\", rf_grid.best_estimator_),\n",
        "    (\"xgb\", xgb_grid.best_estimator_),\n",
        "    (\"cat\", cat_grid.best_estimator_)\n",
        "]\n",
        "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=cv, n_jobs=-1)\n",
        "\n",
        "scores = cross_val_score(stack_model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Stacking CV Accuracy: %.4f ± %.4f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_stack = stack_model.predict(X_test)\n",
        "\n",
        "y_test_labels = le.inverse_transform(y_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred_stack)\n",
        "\n",
        "print(\"Stacking Test Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "\n",
        "f1_fire = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xteEN1NNSWr0",
        "outputId": "f63c486a-e08b-43ff-d5be-1c872057a794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF Params: {'max_depth': None, 'n_estimators': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:58:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGB Params: {'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 200}\n",
            "Best Cat Params: {'depth': 8, 'iterations': 500, 'learning_rate': 0.1}\n",
            "Stacking CV Accuracy: 0.9474 ± 0.0071\n",
            "Stacking Test Accuracy: 0.9593023255813954\n",
            "Overall F1 Score: 0.9591\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       130\n",
            "           1       0.93      0.90      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.95      0.94      0.94       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet Model"
      ],
      "metadata": {
        "id": "9Icmy-KQrgaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_np = X_train_scaled.astype(\"float32\")\n",
        "X_test_np = X_test_scaled.astype(\"float32\")\n",
        "y_train_np = y_train.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# Initialize and Train TabNet\n",
        "clf = TabNetClassifier(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=70,\n",
        "    patience=25,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    weights=sample_weights  # fixes the imbalance\n",
        "\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = clf.predict(X_test_np)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_np, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_np, y_pred))\n",
        "\n",
        "# Plot Feature Importances\n",
        "feature_names = X.columns\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"TabNet Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"F1 Score: {f1_score(y_test_np, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zu6WJfvJfUPd",
        "outputId": "b51ceeb4-998d-47af-b6b9-a12a2c23c061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.96959 | train_accuracy: 0.51462 | valid_accuracy: 0.50581 |  0:00:00s\n",
            "epoch 1  | loss: 0.66358 | train_accuracy: 0.59211 | valid_accuracy: 0.62209 |  0:00:00s\n",
            "epoch 2  | loss: 0.60881 | train_accuracy: 0.66959 | valid_accuracy: 0.6686  |  0:00:00s\n",
            "epoch 3  | loss: 0.5881  | train_accuracy: 0.72953 | valid_accuracy: 0.68605 |  0:00:00s\n",
            "epoch 4  | loss: 0.52717 | train_accuracy: 0.72222 | valid_accuracy: 0.7093  |  0:00:00s\n",
            "epoch 5  | loss: 0.49413 | train_accuracy: 0.72368 | valid_accuracy: 0.68605 |  0:00:01s\n",
            "epoch 6  | loss: 0.50074 | train_accuracy: 0.74708 | valid_accuracy: 0.72674 |  0:00:01s\n",
            "epoch 7  | loss: 0.47484 | train_accuracy: 0.77047 | valid_accuracy: 0.75    |  0:00:01s\n",
            "epoch 8  | loss: 0.43292 | train_accuracy: 0.78801 | valid_accuracy: 0.76163 |  0:00:01s\n",
            "epoch 9  | loss: 0.40556 | train_accuracy: 0.84064 | valid_accuracy: 0.82558 |  0:00:01s\n",
            "epoch 10 | loss: 0.41802 | train_accuracy: 0.83626 | valid_accuracy: 0.82558 |  0:00:01s\n",
            "epoch 11 | loss: 0.3896  | train_accuracy: 0.79386 | valid_accuracy: 0.76163 |  0:00:01s\n",
            "epoch 12 | loss: 0.39007 | train_accuracy: 0.79971 | valid_accuracy: 0.74419 |  0:00:01s\n",
            "epoch 13 | loss: 0.35683 | train_accuracy: 0.81871 | valid_accuracy: 0.77907 |  0:00:02s\n",
            "epoch 14 | loss: 0.42237 | train_accuracy: 0.83041 | valid_accuracy: 0.78488 |  0:00:02s\n",
            "epoch 15 | loss: 0.38807 | train_accuracy: 0.86257 | valid_accuracy: 0.79651 |  0:00:02s\n",
            "epoch 16 | loss: 0.36869 | train_accuracy: 0.88158 | valid_accuracy: 0.80814 |  0:00:02s\n",
            "epoch 17 | loss: 0.37814 | train_accuracy: 0.89766 | valid_accuracy: 0.86047 |  0:00:02s\n",
            "epoch 18 | loss: 0.33609 | train_accuracy: 0.89912 | valid_accuracy: 0.88372 |  0:00:02s\n",
            "epoch 19 | loss: 0.3646  | train_accuracy: 0.91082 | valid_accuracy: 0.88953 |  0:00:02s\n",
            "epoch 20 | loss: 0.34284 | train_accuracy: 0.91667 | valid_accuracy: 0.88953 |  0:00:03s\n",
            "epoch 21 | loss: 0.40296 | train_accuracy: 0.9152  | valid_accuracy: 0.87791 |  0:00:03s\n",
            "epoch 22 | loss: 0.35073 | train_accuracy: 0.90789 | valid_accuracy: 0.89535 |  0:00:03s\n",
            "epoch 23 | loss: 0.33312 | train_accuracy: 0.90351 | valid_accuracy: 0.87791 |  0:00:03s\n",
            "epoch 24 | loss: 0.35047 | train_accuracy: 0.89035 | valid_accuracy: 0.87791 |  0:00:03s\n",
            "epoch 25 | loss: 0.37448 | train_accuracy: 0.8962  | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 26 | loss: 0.36435 | train_accuracy: 0.89766 | valid_accuracy: 0.93023 |  0:00:03s\n",
            "epoch 27 | loss: 0.3636  | train_accuracy: 0.8538  | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 28 | loss: 0.30962 | train_accuracy: 0.88158 | valid_accuracy: 0.91279 |  0:00:04s\n",
            "epoch 29 | loss: 0.3402  | train_accuracy: 0.90497 | valid_accuracy: 0.9186  |  0:00:04s\n",
            "epoch 30 | loss: 0.33953 | train_accuracy: 0.91667 | valid_accuracy: 0.92442 |  0:00:04s\n",
            "epoch 31 | loss: 0.31677 | train_accuracy: 0.91959 | valid_accuracy: 0.89535 |  0:00:04s\n",
            "epoch 32 | loss: 0.30843 | train_accuracy: 0.92105 | valid_accuracy: 0.90698 |  0:00:04s\n",
            "epoch 33 | loss: 0.29902 | train_accuracy: 0.91228 | valid_accuracy: 0.93605 |  0:00:04s\n",
            "epoch 34 | loss: 0.30287 | train_accuracy: 0.91667 | valid_accuracy: 0.92442 |  0:00:04s\n",
            "epoch 35 | loss: 0.29169 | train_accuracy: 0.91667 | valid_accuracy: 0.9186  |  0:00:04s\n",
            "epoch 36 | loss: 0.33445 | train_accuracy: 0.90789 | valid_accuracy: 0.89535 |  0:00:05s\n",
            "epoch 37 | loss: 0.26482 | train_accuracy: 0.91228 | valid_accuracy: 0.91279 |  0:00:05s\n",
            "epoch 38 | loss: 0.31379 | train_accuracy: 0.9152  | valid_accuracy: 0.90116 |  0:00:05s\n",
            "epoch 39 | loss: 0.2863  | train_accuracy: 0.91813 | valid_accuracy: 0.93023 |  0:00:05s\n",
            "epoch 40 | loss: 0.28941 | train_accuracy: 0.90789 | valid_accuracy: 0.93023 |  0:00:05s\n",
            "epoch 41 | loss: 0.32044 | train_accuracy: 0.86404 | valid_accuracy: 0.87209 |  0:00:05s\n",
            "epoch 42 | loss: 0.31874 | train_accuracy: 0.84649 | valid_accuracy: 0.8314  |  0:00:05s\n",
            "epoch 43 | loss: 0.33777 | train_accuracy: 0.86696 | valid_accuracy: 0.84884 |  0:00:05s\n",
            "epoch 44 | loss: 0.33029 | train_accuracy: 0.88012 | valid_accuracy: 0.85465 |  0:00:05s\n",
            "epoch 45 | loss: 0.26574 | train_accuracy: 0.8845  | valid_accuracy: 0.88953 |  0:00:06s\n",
            "epoch 46 | loss: 0.28199 | train_accuracy: 0.8962  | valid_accuracy: 0.90698 |  0:00:06s\n",
            "epoch 47 | loss: 0.25117 | train_accuracy: 0.90789 | valid_accuracy: 0.88953 |  0:00:06s\n",
            "epoch 48 | loss: 0.31125 | train_accuracy: 0.89181 | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 49 | loss: 0.28388 | train_accuracy: 0.8845  | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 50 | loss: 0.245   | train_accuracy: 0.89035 | valid_accuracy: 0.89535 |  0:00:06s\n",
            "epoch 51 | loss: 0.24625 | train_accuracy: 0.8962  | valid_accuracy: 0.89535 |  0:00:06s\n",
            "epoch 52 | loss: 0.25757 | train_accuracy: 0.90789 | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 53 | loss: 0.26351 | train_accuracy: 0.90497 | valid_accuracy: 0.88372 |  0:00:07s\n",
            "epoch 54 | loss: 0.26658 | train_accuracy: 0.89035 | valid_accuracy: 0.88372 |  0:00:07s\n",
            "epoch 55 | loss: 0.24475 | train_accuracy: 0.89327 | valid_accuracy: 0.88953 |  0:00:07s\n",
            "epoch 56 | loss: 0.25243 | train_accuracy: 0.88596 | valid_accuracy: 0.87209 |  0:00:07s\n",
            "epoch 57 | loss: 0.24037 | train_accuracy: 0.87281 | valid_accuracy: 0.86628 |  0:00:07s\n",
            "epoch 58 | loss: 0.26313 | train_accuracy: 0.87865 | valid_accuracy: 0.85465 |  0:00:07s\n",
            "\n",
            "Early stopping occurred at epoch 58 with best_epoch = 33 and best_valid_accuracy = 0.93605\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       130\n",
            "           1       0.88      0.86      0.87        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.92      0.91      0.91       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n",
            "Confusion Matrix:\n",
            " [[125   5]\n",
            " [  6  36]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Oversample"
      ],
      "metadata": {
        "id": "G198Z_Sz4i8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance the training data by oversampling the minority class\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
        "print(\"Class distribution after RandomOverSampler:\", Counter(y_train_res))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_TNZXK-4h_4",
        "outputId": "e4bc0da9-4586-423e-f6c8-8586a6477f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after RandomOverSampler: Counter({0: 516, 1: 516})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "w4r6MbaHORF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define a grid of hyperparameters to search over\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 5],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Display the best hyperparameter and accuracy combination found during the search\n",
        "print(\"Best params:\", grid_rf.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_rf.best_score_)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "cv_scores = cross_val_score(best_rf, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "f1_fire = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTYGzztk4oR7",
        "outputId": "66ac0078-a7a2-42eb-b490-bd28f41be3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best CV Accuracy: 0.9506026921814174\n",
            "CV Scores: [0.92753623 0.95169082 0.94174757 0.96601942 0.96601942]\n",
            "Mean CV: 0.9506026921814174\n",
            "Test Accuracy: 0.9534883720930233\n",
            " Overall F1 Score: 0.9535\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       130\n",
            "           1       0.90      0.90      0.90        42\n",
            "\n",
            "    accuracy                           0.95       172\n",
            "   macro avg       0.94      0.94      0.94       172\n",
            "weighted avg       0.95      0.95      0.95       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "TgPS56tTOKkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid = {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l2\"]}\n",
        "grid_log = GridSearchCV(log_reg, param_grid, cv=cv, scoring=\"accuracy\")\n",
        "grid_log.fit(X_train_res_scaled, y_train_res)\n",
        "\n",
        "print(\"Best params:\", grid_log.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_log.best_score_)\n",
        "\n",
        "best_log = grid_log.best_estimator_\n",
        "cv_scores = cross_val_score(best_log, X_train_res_scaled, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_log = best_log.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
        "\n",
        "f1_fire = f1_score(y_test, y_pred_log, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JHlZRu6Nr07",
        "outputId": "c05c48b8-4e3e-4148-b91e-432958230db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 0.01, 'penalty': 'l2'}\n",
            "Best CV Accuracy: 0.8110313775151259\n",
            "CV Scores: [0.8115942  0.76328502 0.82038835 0.82038835 0.84951456]\n",
            "Mean CV: 0.8130340978378123\n",
            "Test Accuracy: 0.8662790697674418\n",
            "Overall F1 Score: 0.8668\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91       130\n",
            "           1       0.72      0.74      0.73        42\n",
            "\n",
            "    accuracy                           0.87       172\n",
            "   macro avg       0.82      0.82      0.82       172\n",
            "weighted avg       0.87      0.87      0.87       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "kp0U6qheOeti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"kernel\": [\"linear\", \"rbf\"],\n",
        "    \"gamma\": [\"scale\", \"auto\"]\n",
        "}\n",
        "grid_svm = GridSearchCV(svm, param_grid, cv=5, scoring=\"accuracy\")\n",
        "grid_svm.fit(X_train_res_scaled, y_train_res)\n",
        "\n",
        "print(\"Best params:\", grid_svm.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_svm.best_score_)\n",
        "\n",
        "best_svm = grid_svm.best_estimator_\n",
        "cv_scores = cross_val_score(best_svm, X_train_res_scaled, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_svm = best_svm.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "\n",
        "f1_fire = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5CWUoTSOI3K",
        "outputId": "e6b6d152-9317-4420-f450-5b5e5c12a66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best CV Accuracy: 0.8789034285446273\n",
            "CV Scores: [0.84541063 0.88405797 0.86407767 0.89805825 0.90291262]\n",
            "Mean CV: 0.8789034285446273\n",
            "Test Accuracy: 0.936046511627907\n",
            "Overall F1 Score: 0.9358\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       130\n",
            "           1       0.88      0.86      0.87        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.92      0.91      0.91       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost  \" model selection \""
      ],
      "metadata": {
        "id": "wLyz9qbmPGsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "grid_xgb = GridSearchCV(xgb, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_xgb.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best params:\", grid_xgb.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_xgb.best_score_)\n",
        "\n",
        "best_xgb1 = grid_xgb.best_estimator_\n",
        "cv_scores = cross_val_score(best_xgb1, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_xgb = best_xgb1.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_enc, y_pred_xgb))\n",
        "\n",
        "f1_fire = f1_score(y_test_enc, y_pred_xgb, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4fV6o_QOhJQ",
        "outputId": "ae779caa-86e1-4485-f2f5-75681f537989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Best CV Accuracy: 0.9835232869002392\n",
            "CV Scores: [0.98550725 0.98550725 0.98058252 0.99029126 0.97572816]\n",
            "Mean CV: 0.9835232869002392\n",
            "Test Accuracy: 0.9709302325581395\n",
            "Overall F1 Score: 0.9708\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       130\n",
            "           1       0.95      0.93      0.94        42\n",
            "\n",
            "    accuracy                           0.97       172\n",
            "   macro avg       0.96      0.96      0.96       172\n",
            "weighted avg       0.97      0.97      0.97       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model to use it in our system 'Nuthur'"
      ],
      "metadata": {
        "id": "e5S7IDtxPeLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_xgb1, \"best_xgb_model.pkl\")\n",
        "print(\" created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwRZ1qMnPU39",
        "outputId": "04cd52ab-2d96-4155-cb0b-53dd259f8df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "lVBfQD9ysCJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_cat = GridSearchCV(\n",
        "    estimator=catboost,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_cat.fit(X_train_res, y_train_res)\n",
        "print(\"Best Parameters:\", grid_cat.best_params_)\n",
        "print(\"Best CV Accuracy:\", round(grid_cat.best_score_, 4))\n",
        "\n",
        "best_cat = grid_cat.best_estimator_\n",
        "cv_scores = cross_val_score(best_cat, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
        "print(\" Mean CV Accuracy:\", round(cv_scores.mean(), 4))\n",
        "\n",
        "y_pred = best_cat.predict(X_test)\n",
        "print(\"\\nTest Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "\n",
        "f1_fire = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqpqYiGCP2w7",
        "outputId": "7560fffa-5891-4031-de28-bd52b2b40567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "Best Parameters: {'depth': 8, 'iterations': 400, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
            "Best CV Accuracy: 0.9874\n",
            "\n",
            "Cross-Validation Scores: [0.98550725 0.97584541 0.98543689 0.99514563 0.99514563]\n",
            " Mean CV Accuracy: 0.9874\n",
            "\n",
            "Test Accuracy: 0.9593\n",
            " Overall F1 Score: 0.9595\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       130\n",
            "           1       0.91      0.93      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.94      0.95      0.95       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensamble Learning for the best 3 models"
      ],
      "metadata": {
        "id": "m5i1b8RwQn9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=3,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(C=1, kernel='rbf', probability=True, random_state=42))  # استخدم أفضل باراميتراتك\n",
        "])\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catboost', catboost_model),\n",
        "        ('svm', svm_pipeline),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred_ensemble = voting_clf.predict(X_test)\n",
        "\n",
        "y_test_labels = le.inverse_transform(y_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred_ensemble)\n",
        "\n",
        "print(\"Ensemble Test Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "f1_fire = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nEnsemble Classification Report:\\n\",classification_report(y_test_labels, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3fMNuWjQdZo",
        "outputId": "b7b72d48-aa45-4d46-d252-ea27b573aea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.9593023255813954\n",
            "Overall F1 Score: 0.9595\n",
            "\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       130\n",
            "           1       0.91      0.93      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.94      0.95      0.95       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking Classifier\n"
      ],
      "metadata": {
        "id": "xYPeuXGrXNnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stratified 5-fold cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Random Forest model tuning\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {\"n_estimators\": [100, 200], \"max_depth\": [None, 10, 20]}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best RF Params:\", rf_grid.best_params_)\n",
        "\n",
        "# XGBoost model tuning with scaling in a pipeline\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "xgb_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", xgb)])\n",
        "xgb_params = {\n",
        "    \"clf__n_estimators\": [100, 200],\n",
        "    \"clf__max_depth\": [3, 5, 7],\n",
        "    \"clf__learning_rate\": [0.01, 0.1]\n",
        "}\n",
        "xgb_grid = GridSearchCV(xgb_pipe, xgb_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "xgb_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best XGB Params:\", xgb_grid.best_params_)\n",
        "\n",
        "# CatBoost model tuning\n",
        "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "cat_params = {\"iterations\": [200, 500], \"depth\": [4, 6, 8], \"learning_rate\": [0.01, 0.1]}\n",
        "cat_grid = GridSearchCV(cat, cat_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "cat_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best Cat Params:\", cat_grid.best_params_)\n",
        "\n",
        "# Build stacking model using the best estimators\n",
        "estimators = [\n",
        "    (\"rf\", rf_grid.best_estimator_),\n",
        "    (\"xgb\", xgb_grid.best_estimator_),\n",
        "    (\"cat\", cat_grid.best_estimator_)\n",
        "]\n",
        "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=cv, n_jobs=-1)\n",
        "\n",
        "# Cross-validation performance of stacking model\n",
        "scores = cross_val_score(stack_model, X_train_res, y_train_res, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Stacking CV Accuracy: %.4f ± %.4f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "# Train and evaluate on test data\n",
        "stack_model.fit(X_train_res, y_train_res)\n",
        "y_pred_stack = stack_model.predict(X_test)\n",
        "\n",
        "# Decode labels and evaluate performance\n",
        "y_test_labels = le.inverse_transform(y_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred_stack)\n",
        "\n",
        "print(\"Stacking Test Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "f1_fire = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "terYueSXSZdr",
        "outputId": "001cec9e-c692-496d-e5cb-1eb00f245f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF Params: {'max_depth': None, 'n_estimators': 200}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:50:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGB Params: {'clf__learning_rate': 0.1, 'clf__max_depth': 7, 'clf__n_estimators': 200}\n",
            "Best Cat Params: {'depth': 8, 'iterations': 200, 'learning_rate': 0.1}\n",
            "Stacking CV Accuracy: 0.9826 ± 0.0095\n",
            "Stacking Test Accuracy: 0.9651162790697675\n",
            "Overall F1 Score: 0.9651\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       130\n",
            "           1       0.93      0.93      0.93        42\n",
            "\n",
            "    accuracy                           0.97       172\n",
            "   macro avg       0.95      0.95      0.95       172\n",
            "weighted avg       0.97      0.97      0.97       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet model"
      ],
      "metadata": {
        "id": "r8cq7TL7oLFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FEATURE SCALING\n",
        "scaler = StandardScaler()\n",
        "X_train_np = scaler.fit_transform(X_train_res).astype(np.float32)\n",
        "X_test_np = scaler.transform(X_test).astype(np.float32)\n",
        "y_train_np = y_train_res.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# INITIALIZE TABNET\n",
        "clf = TabNetClassifier(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# TRAIN TABNET\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=70,\n",
        "    patience=25,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# EVALUATION\n",
        "y_pred = clf.predict(X_test_np)\n",
        "\n",
        "print(f\"F1 Score (OverSampling): {f1_score(y_test_np, y_pred, average='weighted'):.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_np, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_np, y_pred))\n",
        "\n",
        "# FEATURE IMPORTANCE\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X.columns, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"TabNet Feature Importances (OverSampling)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D0Zkmdf2gl80",
        "outputId": "f96c92d5-2e38-4865-daa0-3484c1d11090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.90672 | train_accuracy: 0.63857 | valid_accuracy: 0.72674 |  0:00:00s\n",
            "epoch 1  | loss: 0.65799 | train_accuracy: 0.76744 | valid_accuracy: 0.72674 |  0:00:00s\n",
            "epoch 2  | loss: 0.53549 | train_accuracy: 0.74031 | valid_accuracy: 0.78488 |  0:00:00s\n",
            "epoch 3  | loss: 0.5114  | train_accuracy: 0.75484 | valid_accuracy: 0.77907 |  0:00:01s\n",
            "epoch 4  | loss: 0.482   | train_accuracy: 0.73159 | valid_accuracy: 0.79651 |  0:00:01s\n",
            "epoch 5  | loss: 0.48814 | train_accuracy: 0.75194 | valid_accuracy: 0.80233 |  0:00:01s\n",
            "epoch 6  | loss: 0.47993 | train_accuracy: 0.75194 | valid_accuracy: 0.8314  |  0:00:01s\n",
            "epoch 7  | loss: 0.42669 | train_accuracy: 0.78004 | valid_accuracy: 0.84302 |  0:00:02s\n",
            "epoch 8  | loss: 0.4042  | train_accuracy: 0.8062  | valid_accuracy: 0.83721 |  0:00:02s\n",
            "epoch 9  | loss: 0.39878 | train_accuracy: 0.81492 | valid_accuracy: 0.83721 |  0:00:02s\n",
            "epoch 10 | loss: 0.38434 | train_accuracy: 0.85174 | valid_accuracy: 0.89535 |  0:00:02s\n",
            "epoch 11 | loss: 0.36242 | train_accuracy: 0.86434 | valid_accuracy: 0.90116 |  0:00:02s\n",
            "epoch 12 | loss: 0.36665 | train_accuracy: 0.86628 | valid_accuracy: 0.89535 |  0:00:03s\n",
            "epoch 13 | loss: 0.36212 | train_accuracy: 0.85562 | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 14 | loss: 0.32949 | train_accuracy: 0.88178 | valid_accuracy: 0.88953 |  0:00:03s\n",
            "epoch 15 | loss: 0.35009 | train_accuracy: 0.88081 | valid_accuracy: 0.88953 |  0:00:03s\n",
            "epoch 16 | loss: 0.33786 | train_accuracy: 0.86628 | valid_accuracy: 0.88953 |  0:00:03s\n",
            "epoch 17 | loss: 0.32586 | train_accuracy: 0.87016 | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 18 | loss: 0.31537 | train_accuracy: 0.88469 | valid_accuracy: 0.87791 |  0:00:04s\n",
            "epoch 19 | loss: 0.34428 | train_accuracy: 0.87403 | valid_accuracy: 0.90116 |  0:00:04s\n",
            "epoch 20 | loss: 0.33749 | train_accuracy: 0.87597 | valid_accuracy: 0.9186  |  0:00:04s\n",
            "epoch 21 | loss: 0.32548 | train_accuracy: 0.87888 | valid_accuracy: 0.92442 |  0:00:04s\n",
            "epoch 22 | loss: 0.30427 | train_accuracy: 0.89438 | valid_accuracy: 0.87791 |  0:00:04s\n",
            "epoch 23 | loss: 0.32591 | train_accuracy: 0.87597 | valid_accuracy: 0.86628 |  0:00:05s\n",
            "epoch 24 | loss: 0.30373 | train_accuracy: 0.86434 | valid_accuracy: 0.86628 |  0:00:05s\n",
            "epoch 25 | loss: 0.30444 | train_accuracy: 0.86822 | valid_accuracy: 0.86047 |  0:00:05s\n",
            "epoch 26 | loss: 0.28303 | train_accuracy: 0.8876  | valid_accuracy: 0.88372 |  0:00:05s\n",
            "epoch 27 | loss: 0.29559 | train_accuracy: 0.88857 | valid_accuracy: 0.90116 |  0:00:05s\n",
            "epoch 28 | loss: 0.30808 | train_accuracy: 0.88178 | valid_accuracy: 0.9186  |  0:00:06s\n",
            "epoch 29 | loss: 0.27734 | train_accuracy: 0.89438 | valid_accuracy: 0.9186  |  0:00:06s\n",
            "epoch 30 | loss: 0.29365 | train_accuracy: 0.8905  | valid_accuracy: 0.88953 |  0:00:06s\n",
            "epoch 31 | loss: 0.30501 | train_accuracy: 0.8876  | valid_accuracy: 0.91279 |  0:00:06s\n",
            "epoch 32 | loss: 0.27111 | train_accuracy: 0.88081 | valid_accuracy: 0.91279 |  0:00:06s\n",
            "epoch 33 | loss: 0.26694 | train_accuracy: 0.89729 | valid_accuracy: 0.90698 |  0:00:06s\n",
            "epoch 34 | loss: 0.28996 | train_accuracy: 0.87888 | valid_accuracy: 0.89535 |  0:00:07s\n",
            "epoch 35 | loss: 0.30555 | train_accuracy: 0.8876  | valid_accuracy: 0.88372 |  0:00:07s\n",
            "epoch 36 | loss: 0.27809 | train_accuracy: 0.86531 | valid_accuracy: 0.86628 |  0:00:07s\n",
            "epoch 37 | loss: 0.30322 | train_accuracy: 0.89147 | valid_accuracy: 0.87791 |  0:00:07s\n",
            "epoch 38 | loss: 0.2812  | train_accuracy: 0.87112 | valid_accuracy: 0.86047 |  0:00:07s\n",
            "epoch 39 | loss: 0.28934 | train_accuracy: 0.87209 | valid_accuracy: 0.85465 |  0:00:07s\n",
            "epoch 40 | loss: 0.31169 | train_accuracy: 0.85756 | valid_accuracy: 0.86628 |  0:00:08s\n",
            "epoch 41 | loss: 0.30188 | train_accuracy: 0.87694 | valid_accuracy: 0.87209 |  0:00:08s\n",
            "epoch 42 | loss: 0.319   | train_accuracy: 0.86822 | valid_accuracy: 0.86628 |  0:00:08s\n",
            "epoch 43 | loss: 0.31013 | train_accuracy: 0.85853 | valid_accuracy: 0.81395 |  0:00:08s\n",
            "epoch 44 | loss: 0.31715 | train_accuracy: 0.87791 | valid_accuracy: 0.84884 |  0:00:08s\n",
            "epoch 45 | loss: 0.2847  | train_accuracy: 0.87694 | valid_accuracy: 0.87209 |  0:00:09s\n",
            "epoch 46 | loss: 0.28646 | train_accuracy: 0.88857 | valid_accuracy: 0.89535 |  0:00:09s\n",
            "\n",
            "Early stopping occurred at epoch 46 with best_epoch = 21 and best_valid_accuracy = 0.92442\n",
            "F1 Score (OverSampling): 0.9253\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95       130\n",
            "           1       0.82      0.88      0.85        42\n",
            "\n",
            "    accuracy                           0.92       172\n",
            "   macro avg       0.89      0.91      0.90       172\n",
            "weighted avg       0.93      0.92      0.93       172\n",
            "\n",
            "Confusion Matrix:\n",
            " [[122   8]\n",
            " [  5  37]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Undersampling"
      ],
      "metadata": {
        "id": "KdJP4dsgV7Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
        "print(\"Class distribution after RandomUnderSampler:\", Counter(y_train_res))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzSam7A2V-mF",
        "outputId": "861b3b8d-46f4-4bc3-cbfa-a5323a0c70e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after RandomUnderSampler: Counter({0: 168, 1: 168})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Models and Hyperparameter Grids for GridSearchCV"
      ],
      "metadata": {
        "id": "fLJWeDspdoZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"SVM\": SVC(),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"RandomForest\": {\n",
        "        \"n_estimators\": [100],\n",
        "        \"max_depth\": [5, 10],\n",
        "        \"min_samples_split\": [2],\n",
        "        \"min_samples_leaf\": [1],\n",
        "        \"max_features\": [\"sqrt\"]\n",
        "    },\n",
        "    \"LogisticRegression\": {\n",
        "        \"C\": [0.1, 1, 10]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"C\": [1, 10],\n",
        "        \"kernel\": [\"rbf\", \"linear\"]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"n_estimators\": [100],\n",
        "        \"max_depth\": [3, 5]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "4fCuRwbhWdzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model using GridSearchCV\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nModel: {name}\")\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid = GridSearchCV(model, param_grids[name], cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid.fit(X_train_res, y_train_res)\n",
        "\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "    print(\"Best CV Accuracy:\", grid.best_score_)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Test performance\n",
        "    print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(f\"Overall F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLhVGAmWWile",
        "outputId": "dbbe4cd1-faea-45ed-86d0-130cd17330a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: RandomForest\n",
            "Best params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best CV Accuracy: 0.8600087796312555\n",
            "Test Accuracy: 0.936046511627907\n",
            "Overall F1 Score: 0.9372\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       130\n",
            "           1       0.83      0.93      0.88        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.90      0.93      0.92       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n",
            "\n",
            "Model: LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 10}\n",
            "Best CV Accuracy: 0.7829675153643547\n",
            "Test Accuracy: 0.877906976744186\n",
            "Overall F1 Score: 0.8752\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       130\n",
            "           1       0.78      0.69      0.73        42\n",
            "\n",
            "    accuracy                           0.88       172\n",
            "   macro avg       0.84      0.81      0.83       172\n",
            "weighted avg       0.87      0.88      0.88       172\n",
            "\n",
            "\n",
            "Model: SVM\n",
            "Best params: {'C': 1, 'kernel': 'linear'}\n",
            "Best CV Accuracy: 0.7975417032484635\n",
            "Test Accuracy: 0.9011627906976745\n",
            "Overall F1 Score: 0.8990\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94       130\n",
            "           1       0.84      0.74      0.78        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.88      0.85      0.86       172\n",
            "weighted avg       0.90      0.90      0.90       172\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Best params: {'max_depth': 3, 'n_estimators': 100}\n",
            "Best CV Accuracy: 0.872036874451273\n",
            "Test Accuracy: 0.9186046511627907\n",
            "Overall F1 Score: 0.9209\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.94       130\n",
            "           1       0.78      0.93      0.85        42\n",
            "\n",
            "    accuracy                           0.92       172\n",
            "   macro avg       0.88      0.92      0.90       172\n",
            "weighted avg       0.93      0.92      0.92       172\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:58:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "-5eQt3KDaxIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_cat = GridSearchCV(\n",
        "    estimator=catboost,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_cat.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\" Best Parameters:\", grid_cat.best_params_)\n",
        "print(\" Best CV Accuracy:\", round(grid_cat.best_score_, 4))\n",
        "\n",
        "best_cat = grid_cat.best_estimator_\n",
        "\n",
        "cv_scores = cross_val_score(best_cat, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"\\nCross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", round(cv_scores.mean(), 4))\n",
        "\n",
        "y_pred_catb = best_cat.predict(X_test)\n",
        "\n",
        "print(\"\\nTest Accuracy:\", round(accuracy_score(y_test, y_pred_catb), 4))\n",
        "f1_fire = f1_score(y_test, y_pred_catb, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred_catb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPt1asBfZNIq",
        "outputId": "ba71df46-35a9-4ad6-ac20-de1586b96982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            " Best Parameters: {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
            " Best CV Accuracy: 0.8899\n",
            "\n",
            "Cross-Validation Scores: [0.88235294 0.89552239 0.89552239 0.92537313 0.85074627]\n",
            "Mean CV Accuracy: 0.8899\n",
            "\n",
            "Test Accuracy: 0.9186\n",
            " Overall F1 Score: 0.9209\n",
            "\n",
            " Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.94       130\n",
            "           1       0.78      0.93      0.85        42\n",
            "\n",
            "    accuracy                           0.92       172\n",
            "   macro avg       0.88      0.92      0.90       172\n",
            "weighted avg       0.93      0.92      0.92       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensamble Learning for the best 3 models"
      ],
      "metadata": {
        "id": "lWldFmGMazqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=3,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(C=1, kernel='rbf', probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catboost', catboost_model),\n",
        "        ('svm', svm_pipeline),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    voting='soft',  # soft voting\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "y_pred_ensemble = voting_clf.predict(X_test)\n",
        "\n",
        "y_test_labels = le.inverse_transform(y_test_enc)\n",
        "y_pred_labels = le.inverse_transform(y_pred_ensemble)\n",
        "\n",
        "print(\"Ensemble Test Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "f1_fire = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nEnsemble Classification Report:\\n\",\n",
        "      classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Yt5Ke7ZdJs",
        "outputId": "0ee5c517-5e3c-4762-808e-cc8ca6dfb24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.936046511627907\n",
            "Overall F1 Score: 0.9372\n",
            "\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       130\n",
            "           1       0.83      0.93      0.88        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.90      0.93      0.92       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Staking Ensamble"
      ],
      "metadata": {
        "id": "x0ZF9OnKa9Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5-fold stratified cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {\"n_estimators\": [100, 200], \"max_depth\": [None, 10, 20]}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best RF Params:\", rf_grid.best_params_)\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "xgb_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", xgb)])\n",
        "xgb_params = {\n",
        "    \"clf__n_estimators\": [100, 200],\n",
        "    \"clf__max_depth\": [3, 5, 7],\n",
        "    \"clf__learning_rate\": [0.01, 0.1]\n",
        "}\n",
        "xgb_grid = GridSearchCV(xgb_pipe, xgb_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "xgb_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best XGB Params:\", xgb_grid.best_params_)\n",
        "\n",
        "\n",
        "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "cat_params = {\"iterations\": [200, 500], \"depth\": [4, 6, 8], \"learning_rate\": [0.01, 0.1]}\n",
        "cat_grid = GridSearchCV(cat, cat_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "cat_grid.fit(X_train_res, y_train_res)\n",
        "print(\"Best Cat Params:\", cat_grid.best_params_)\n",
        "\n",
        "# Build stacking model using best estimators\n",
        "estimators = [\n",
        "    (\"rf\", rf_grid.best_estimator_),\n",
        "    (\"xgb\", xgb_grid.best_estimator_),\n",
        "    (\"cat\", cat_grid.best_estimator_)\n",
        "]\n",
        "# Create a stacking ensemble with Logistic Regression as the meta-model\n",
        "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=cv, n_jobs=-1)\n",
        "\n",
        "# Cross-validation results\n",
        "scores = cross_val_score(stack_model, X_train_res, y_train_res, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Stacking CV Accuracy: %.4f ± %.4f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "# Train and test performance\n",
        "stack_model.fit(X_train_res, y_train_res)\n",
        "y_pred_stack = stack_model.predict(X_test)\n",
        "\n",
        "# Decode and evaluate\n",
        "y_test_labels = le.inverse_transform(y_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred_stack)\n",
        "print(\"Stacking Test Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
        "f1_fire = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I99oh-u5aQe_",
        "outputId": "8218a926-a1da-4d92-ae3e-6f5b40e754e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF Params: {'max_depth': None, 'n_estimators': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [18:17:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGB Params: {'clf__learning_rate': 0.01, 'clf__max_depth': 7, 'clf__n_estimators': 100}\n",
            "Best Cat Params: {'depth': 8, 'iterations': 500, 'learning_rate': 0.1}\n",
            "Stacking CV Accuracy: 0.8781 ± 0.0454\n",
            "Stacking Test Accuracy: 0.9244186046511628\n",
            "Overall F1 Score: 0.9267\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.92      0.95       130\n",
            "           1       0.78      0.95      0.86        42\n",
            "\n",
            "    accuracy                           0.92       172\n",
            "   macro avg       0.88      0.93      0.90       172\n",
            "weighted avg       0.93      0.92      0.93       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning"
      ],
      "metadata": {
        "id": "YFk7diKOfta6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet Model"
      ],
      "metadata": {
        "id": "LA5LfLLepeXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  FEATURE SCALING\n",
        "scaler = StandardScaler()\n",
        "X_train_np = scaler.fit_transform(X_train_res).astype(np.float32)\n",
        "X_test_np = scaler.transform(X_test).astype(np.float32)\n",
        "y_train_np = y_train_res.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# INITIALIZE TABNET\n",
        "clf = TabNetClassifier(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# TRAIN TABNET\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=70,\n",
        "    patience=25,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# EVALUATION\n",
        "y_pred = clf.predict(X_test_np)\n",
        "\n",
        "print(f\"F1 Score (UnderSampling): {f1_score(y_test_np, y_pred, average='weighted'):.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_np, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_np, y_pred))\n",
        "\n",
        "# FEATURE IMPORTANCE\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X.columns, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"TabNet Feature Importances (UnderSampling)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d08Qyfyno67k",
        "outputId": "5360c752-b762-4b7f-8b32-496857b37f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.13282 | train_accuracy: 0.44048 | valid_accuracy: 0.39535 |  0:00:00s\n",
            "epoch 1  | loss: 0.78413 | train_accuracy: 0.48512 | valid_accuracy: 0.48256 |  0:00:00s\n",
            "epoch 2  | loss: 0.72751 | train_accuracy: 0.47321 | valid_accuracy: 0.51163 |  0:00:00s\n",
            "epoch 3  | loss: 0.65746 | train_accuracy: 0.5625  | valid_accuracy: 0.54651 |  0:00:00s\n",
            "epoch 4  | loss: 0.61029 | train_accuracy: 0.62798 | valid_accuracy: 0.61628 |  0:00:00s\n",
            "epoch 5  | loss: 0.60416 | train_accuracy: 0.68155 | valid_accuracy: 0.67442 |  0:00:00s\n",
            "epoch 6  | loss: 0.5623  | train_accuracy: 0.70536 | valid_accuracy: 0.73837 |  0:00:01s\n",
            "epoch 7  | loss: 0.55766 | train_accuracy: 0.72917 | valid_accuracy: 0.73256 |  0:00:01s\n",
            "epoch 8  | loss: 0.53366 | train_accuracy: 0.72024 | valid_accuracy: 0.69767 |  0:00:01s\n",
            "epoch 9  | loss: 0.51804 | train_accuracy: 0.70238 | valid_accuracy: 0.70349 |  0:00:01s\n",
            "epoch 10 | loss: 0.54051 | train_accuracy: 0.6994  | valid_accuracy: 0.72093 |  0:00:01s\n",
            "epoch 11 | loss: 0.5023  | train_accuracy: 0.72917 | valid_accuracy: 0.78488 |  0:00:01s\n",
            "epoch 12 | loss: 0.48475 | train_accuracy: 0.72619 | valid_accuracy: 0.7907  |  0:00:01s\n",
            "epoch 13 | loss: 0.4777  | train_accuracy: 0.75893 | valid_accuracy: 0.82558 |  0:00:02s\n",
            "epoch 14 | loss: 0.45494 | train_accuracy: 0.76488 | valid_accuracy: 0.86047 |  0:00:02s\n",
            "epoch 15 | loss: 0.46039 | train_accuracy: 0.78869 | valid_accuracy: 0.86628 |  0:00:02s\n",
            "epoch 16 | loss: 0.43137 | train_accuracy: 0.78869 | valid_accuracy: 0.87209 |  0:00:02s\n",
            "epoch 17 | loss: 0.45546 | train_accuracy: 0.80952 | valid_accuracy: 0.88372 |  0:00:02s\n",
            "epoch 18 | loss: 0.38671 | train_accuracy: 0.81548 | valid_accuracy: 0.87791 |  0:00:02s\n",
            "epoch 19 | loss: 0.42066 | train_accuracy: 0.82143 | valid_accuracy: 0.86628 |  0:00:02s\n",
            "epoch 20 | loss: 0.40419 | train_accuracy: 0.83036 | valid_accuracy: 0.86628 |  0:00:03s\n",
            "epoch 21 | loss: 0.38464 | train_accuracy: 0.82738 | valid_accuracy: 0.86047 |  0:00:03s\n",
            "epoch 22 | loss: 0.39075 | train_accuracy: 0.82143 | valid_accuracy: 0.86628 |  0:00:03s\n",
            "epoch 23 | loss: 0.3873  | train_accuracy: 0.80357 | valid_accuracy: 0.85465 |  0:00:03s\n",
            "epoch 24 | loss: 0.3759  | train_accuracy: 0.80655 | valid_accuracy: 0.84302 |  0:00:03s\n",
            "epoch 25 | loss: 0.38442 | train_accuracy: 0.80952 | valid_accuracy: 0.84302 |  0:00:03s\n",
            "epoch 26 | loss: 0.34017 | train_accuracy: 0.81548 | valid_accuracy: 0.83721 |  0:00:03s\n",
            "epoch 27 | loss: 0.34316 | train_accuracy: 0.82738 | valid_accuracy: 0.84884 |  0:00:04s\n",
            "epoch 28 | loss: 0.36202 | train_accuracy: 0.82738 | valid_accuracy: 0.84884 |  0:00:04s\n",
            "epoch 29 | loss: 0.33918 | train_accuracy: 0.83036 | valid_accuracy: 0.84302 |  0:00:04s\n",
            "epoch 30 | loss: 0.3224  | train_accuracy: 0.83929 | valid_accuracy: 0.83721 |  0:00:04s\n",
            "epoch 31 | loss: 0.36265 | train_accuracy: 0.83333 | valid_accuracy: 0.81977 |  0:00:04s\n",
            "epoch 32 | loss: 0.31325 | train_accuracy: 0.82738 | valid_accuracy: 0.82558 |  0:00:04s\n",
            "epoch 33 | loss: 0.32864 | train_accuracy: 0.83333 | valid_accuracy: 0.80233 |  0:00:04s\n",
            "epoch 34 | loss: 0.30018 | train_accuracy: 0.83929 | valid_accuracy: 0.81977 |  0:00:05s\n",
            "epoch 35 | loss: 0.30134 | train_accuracy: 0.84524 | valid_accuracy: 0.83721 |  0:00:05s\n",
            "epoch 36 | loss: 0.31403 | train_accuracy: 0.84226 | valid_accuracy: 0.84884 |  0:00:05s\n",
            "epoch 37 | loss: 0.28949 | train_accuracy: 0.85119 | valid_accuracy: 0.84302 |  0:00:05s\n",
            "epoch 38 | loss: 0.27729 | train_accuracy: 0.85714 | valid_accuracy: 0.83721 |  0:00:05s\n",
            "epoch 39 | loss: 0.3223  | train_accuracy: 0.8631  | valid_accuracy: 0.84302 |  0:00:05s\n",
            "epoch 40 | loss: 0.34331 | train_accuracy: 0.85119 | valid_accuracy: 0.85465 |  0:00:06s\n",
            "epoch 41 | loss: 0.32487 | train_accuracy: 0.84821 | valid_accuracy: 0.86047 |  0:00:06s\n",
            "epoch 42 | loss: 0.29044 | train_accuracy: 0.85714 | valid_accuracy: 0.84302 |  0:00:06s\n",
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 17 and best_valid_accuracy = 0.88372\n",
            "F1 Score (UnderSampling): 0.8806\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       130\n",
            "           1       0.81      0.69      0.74        42\n",
            "\n",
            "    accuracy                           0.88       172\n",
            "   macro avg       0.85      0.82      0.83       172\n",
            "weighted avg       0.88      0.88      0.88       172\n",
            "\n",
            "Confusion Matrix:\n",
            " [[123   7]\n",
            " [ 13  29]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "6r7tqLLxsTHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape (3D: samples, timesteps, features)\n",
        "X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_lstm = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]),\n",
        "         kernel_regularizer=regularizers.l2(0.001), return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_lstm = model_lstm.fit(\n",
        "    X_train_lstm, y_train_enc,\n",
        "    validation_data=(X_test_lstm, y_test_enc),\n",
        "    epochs=70, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "loss, acc = model_lstm.evaluate(X_test_lstm, y_test_enc, verbose=0)\n",
        "print(\"LSTM Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test_lstm)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n {cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql5mahw3QBl_",
        "outputId": "54aaf210-b5b2-4898-94a6-c7fc82d03f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.7099 - loss: 0.5992 - val_accuracy: 0.7558 - val_loss: 0.4948\n",
            "Epoch 2/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7729 - loss: 0.5022 - val_accuracy: 0.8372 - val_loss: 0.4551\n",
            "Epoch 3/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8077 - loss: 0.4549 - val_accuracy: 0.8663 - val_loss: 0.4257\n",
            "Epoch 4/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8424 - loss: 0.4338 - val_accuracy: 0.8721 - val_loss: 0.4048\n",
            "Epoch 5/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8572 - loss: 0.4038 - val_accuracy: 0.8721 - val_loss: 0.3787\n",
            "Epoch 6/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8392 - loss: 0.4497 - val_accuracy: 0.8895 - val_loss: 0.3612\n",
            "Epoch 7/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8576 - loss: 0.3929 - val_accuracy: 0.8895 - val_loss: 0.3543\n",
            "Epoch 8/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.3854 - val_accuracy: 0.8663 - val_loss: 0.3573\n",
            "Epoch 9/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8725 - loss: 0.3701 - val_accuracy: 0.8779 - val_loss: 0.3424\n",
            "Epoch 10/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8684 - loss: 0.3813 - val_accuracy: 0.8779 - val_loss: 0.3377\n",
            "Epoch 11/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8577 - loss: 0.4030 - val_accuracy: 0.8779 - val_loss: 0.3355\n",
            "Epoch 12/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8962 - loss: 0.3364 - val_accuracy: 0.8779 - val_loss: 0.3309\n",
            "Epoch 13/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8863 - loss: 0.3514 - val_accuracy: 0.8779 - val_loss: 0.3236\n",
            "Epoch 14/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8829 - loss: 0.3535 - val_accuracy: 0.8837 - val_loss: 0.3301\n",
            "Epoch 15/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8820 - loss: 0.3216 - val_accuracy: 0.8837 - val_loss: 0.3202\n",
            "Epoch 16/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8786 - loss: 0.3373 - val_accuracy: 0.8721 - val_loss: 0.3317\n",
            "Epoch 17/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8928 - loss: 0.3244 - val_accuracy: 0.8779 - val_loss: 0.3245\n",
            "Epoch 18/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8929 - loss: 0.3225 - val_accuracy: 0.8953 - val_loss: 0.3060\n",
            "Epoch 19/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9076 - loss: 0.2978 - val_accuracy: 0.8953 - val_loss: 0.3052\n",
            "Epoch 20/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8881 - loss: 0.3226 - val_accuracy: 0.8895 - val_loss: 0.3045\n",
            "Epoch 21/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8919 - loss: 0.3222 - val_accuracy: 0.8953 - val_loss: 0.2993\n",
            "Epoch 22/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8974 - loss: 0.3184 - val_accuracy: 0.8953 - val_loss: 0.2964\n",
            "Epoch 23/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8959 - loss: 0.3273 - val_accuracy: 0.8895 - val_loss: 0.2974\n",
            "Epoch 24/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9067 - loss: 0.2786 - val_accuracy: 0.8779 - val_loss: 0.3191\n",
            "Epoch 25/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9079 - loss: 0.2893 - val_accuracy: 0.8721 - val_loss: 0.3180\n",
            "Epoch 26/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9150 - loss: 0.2837 - val_accuracy: 0.8895 - val_loss: 0.2948\n",
            "Epoch 27/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8907 - loss: 0.3218 - val_accuracy: 0.8953 - val_loss: 0.2872\n",
            "Epoch 28/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8867 - loss: 0.3318 - val_accuracy: 0.8953 - val_loss: 0.2870\n",
            "Epoch 29/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9085 - loss: 0.2868 - val_accuracy: 0.8895 - val_loss: 0.2978\n",
            "Epoch 30/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8993 - loss: 0.2997 - val_accuracy: 0.8953 - val_loss: 0.2891\n",
            "Epoch 31/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9182 - loss: 0.2801 - val_accuracy: 0.8953 - val_loss: 0.2885\n",
            "Epoch 32/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9055 - loss: 0.2941 - val_accuracy: 0.8895 - val_loss: 0.3017\n",
            "Epoch 33/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9148 - loss: 0.2927 - val_accuracy: 0.9012 - val_loss: 0.2984\n",
            "LSTM Test Accuracy: 0.895348846912384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b562c245d00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            " [[127   3]\n",
            " [ 15  27]]\n",
            "\n",
            "Classification Report:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       130\n",
            "           1       0.90      0.64      0.75        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.90      0.81      0.84       172\n",
            "weighted avg       0.90      0.90      0.89       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1D"
      ],
      "metadata": {
        "id": "yAgVSlRpsXrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test_cnn = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "model_cnn = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation=\"relu\",\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_cnn = model_cnn.fit(\n",
        "    X_train_cnn, y_train_enc,\n",
        "    validation_data=(X_test_cnn, y_test_enc),\n",
        "    epochs=50, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "loss, acc = model_cnn.evaluate(X_test_cnn, y_test_enc, verbose=0)\n",
        "print(\"CNN1D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn.predict(X_test_cnn)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7D1-iEDRvqm",
        "outputId": "9bb1c0be-3e91-4369-f282-0413aeda98db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5495 - loss: 130.9913 - val_accuracy: 0.7558 - val_loss: 8.5601\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6163 - loss: 51.4302 - val_accuracy: 0.7558 - val_loss: 10.2711\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6230 - loss: 25.2604 - val_accuracy: 0.7558 - val_loss: 1.6108\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6192 - loss: 15.1715 - val_accuracy: 0.8256 - val_loss: 0.5967\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5901 - loss: 10.9311 - val_accuracy: 0.7558 - val_loss: 0.6098\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6159 - loss: 8.1180 - val_accuracy: 0.7558 - val_loss: 0.6206\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6503 - loss: 3.1443 - val_accuracy: 0.7558 - val_loss: 0.6831\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6828 - loss: 2.6130 - val_accuracy: 0.7558 - val_loss: 0.6685\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6819 - loss: 1.4149 - val_accuracy: 0.7558 - val_loss: 0.6830\n",
            "CNN1D Test Accuracy: 0.8255813717842102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b562c18fec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[113  17]\n",
            " [ 13  29]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.88       130\n",
            "           1       0.63      0.69      0.66        42\n",
            "\n",
            "    accuracy                           0.83       172\n",
            "   macro avg       0.76      0.78      0.77       172\n",
            "weighted avg       0.83      0.83      0.83       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "0aAuy5Aqsbe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mlp = X_train.values\n",
        "X_test_mlp = X_test.values\n",
        "\n",
        "model_mlp = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train_mlp.shape[1],),\n",
        "          kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.6),\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.6),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_mlp.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_mlp = model_mlp.fit(\n",
        "    X_train_mlp, y_train_enc,\n",
        "    validation_data=(X_test_mlp, y_test_enc),\n",
        "    epochs=20, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "loss, acc = model_mlp.evaluate(X_test_mlp, y_test_enc, verbose=0)\n",
        "print(\"MLP Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_mlp.predict(X_test_mlp)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0b5aVQ3Sb2f",
        "outputId": "54af8abf-d434-4d4b-f828-43a01cd550f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6035 - loss: 152.3399 - val_accuracy: 0.7558 - val_loss: 28.6138\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - loss: 91.9284 - val_accuracy: 0.7558 - val_loss: 12.9988\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6529 - loss: 83.9114 - val_accuracy: 0.7558 - val_loss: 2.7905\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6594 - loss: 43.3250 - val_accuracy: 0.3430 - val_loss: 2.3818\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6589 - loss: 36.4663 - val_accuracy: 0.3198 - val_loss: 6.7732\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5790 - loss: 23.8043 - val_accuracy: 0.5233 - val_loss: 0.6909\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 14.3223 - val_accuracy: 0.5000 - val_loss: 0.7086\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6354 - loss: 11.3510 - val_accuracy: 0.7558 - val_loss: 0.6172\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6744 - loss: 7.3571 - val_accuracy: 0.7558 - val_loss: 0.7161\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7004 - loss: 6.4609 - val_accuracy: 0.7558 - val_loss: 0.6833\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6368 - loss: 4.0225 - val_accuracy: 0.6453 - val_loss: 0.7357\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6676 - loss: 4.2883 - val_accuracy: 0.7558 - val_loss: 0.6778\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7162 - loss: 2.2521 - val_accuracy: 0.7558 - val_loss: 0.6629\n",
            "MLP Test Accuracy: 0.7558139562606812\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[130   0]\n",
            " [ 42   0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86       130\n",
            "           1       0.00      0.00      0.00        42\n",
            "\n",
            "    accuracy                           0.76       172\n",
            "   macro avg       0.38      0.50      0.43       172\n",
            "weighted avg       0.57      0.76      0.65       172\n",
            "\n",
            "\n",
            "F1 Score: 0.6507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "ttZLGIzzsirU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN2D: (samples, rows, cols, channels)\n",
        "X_train_cnn2d = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "#buikd the model\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_train_cnn2d, y_train_enc,\n",
        "    validation_data=(X_test_cnn2d, y_test_enc),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test_enc, verbose=0)\n",
        "print(\" CNN2D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\n F1 Score: {f1_fire:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ1m-kYyS6fk",
        "outputId": "05dd8c0e-995b-45d5-c17b-eab6900ab725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7036 - loss: 0.7315 - val_accuracy: 0.7558 - val_loss: 0.6019\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7502 - loss: 0.6525 - val_accuracy: 0.7558 - val_loss: 0.5569\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7662 - loss: 0.5882 - val_accuracy: 0.7965 - val_loss: 0.5190\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.5420 - val_accuracy: 0.8488 - val_loss: 0.4865\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8238 - loss: 0.5162 - val_accuracy: 0.8605 - val_loss: 0.4542\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.4835 - val_accuracy: 0.8721 - val_loss: 0.4388\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8575 - loss: 0.4929 - val_accuracy: 0.8663 - val_loss: 0.4345\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8442 - loss: 0.4966 - val_accuracy: 0.8663 - val_loss: 0.4241\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8513 - loss: 0.4700 - val_accuracy: 0.8663 - val_loss: 0.4176\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8747 - loss: 0.4932 - val_accuracy: 0.8663 - val_loss: 0.4152\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8518 - loss: 0.5071 - val_accuracy: 0.8779 - val_loss: 0.4072\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8726 - loss: 0.4121 - val_accuracy: 0.8837 - val_loss: 0.4038\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8798 - loss: 0.4184 - val_accuracy: 0.8779 - val_loss: 0.3980\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8595 - loss: 0.4363 - val_accuracy: 0.8837 - val_loss: 0.3928\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8470 - loss: 0.4792 - val_accuracy: 0.8837 - val_loss: 0.3885\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8774 - loss: 0.4230 - val_accuracy: 0.8837 - val_loss: 0.3828\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8774 - loss: 0.3977 - val_accuracy: 0.8837 - val_loss: 0.3807\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.4095 - val_accuracy: 0.8895 - val_loss: 0.3796\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8966 - loss: 0.3962 - val_accuracy: 0.8895 - val_loss: 0.3736\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.4181 - val_accuracy: 0.8837 - val_loss: 0.3730\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8836 - loss: 0.4018 - val_accuracy: 0.8895 - val_loss: 0.3680\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - loss: 0.4335 - val_accuracy: 0.8837 - val_loss: 0.3711\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8746 - loss: 0.3916 - val_accuracy: 0.8895 - val_loss: 0.3622\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8992 - loss: 0.3754 - val_accuracy: 0.8895 - val_loss: 0.3570\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8968 - loss: 0.3717 - val_accuracy: 0.8895 - val_loss: 0.3560\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.3995 - val_accuracy: 0.8895 - val_loss: 0.3552\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.3978 - val_accuracy: 0.8895 - val_loss: 0.3571\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8889 - loss: 0.3880 - val_accuracy: 0.8895 - val_loss: 0.3519\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8878 - loss: 0.3612 - val_accuracy: 0.8895 - val_loss: 0.3483\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8898 - loss: 0.3775 - val_accuracy: 0.9012 - val_loss: 0.3468\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8882 - loss: 0.3916 - val_accuracy: 0.8953 - val_loss: 0.3452\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8872 - loss: 0.3887 - val_accuracy: 0.8895 - val_loss: 0.3476\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8848 - loss: 0.4103 - val_accuracy: 0.8779 - val_loss: 0.3535\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8620 - loss: 0.4314 - val_accuracy: 0.8953 - val_loss: 0.3424\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8756 - loss: 0.4033 - val_accuracy: 0.8779 - val_loss: 0.3551\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8611 - loss: 0.4208 - val_accuracy: 0.8895 - val_loss: 0.3398\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8813 - loss: 0.3822 - val_accuracy: 0.8895 - val_loss: 0.3382\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8919 - loss: 0.3554 - val_accuracy: 0.8895 - val_loss: 0.3340\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8995 - loss: 0.3714 - val_accuracy: 0.8895 - val_loss: 0.3307\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3968 - val_accuracy: 0.8837 - val_loss: 0.3369\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8867 - loss: 0.3523 - val_accuracy: 0.9012 - val_loss: 0.3255\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8944 - loss: 0.3494 - val_accuracy: 0.8895 - val_loss: 0.3259\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.3665 - val_accuracy: 0.8953 - val_loss: 0.3283\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8803 - loss: 0.4021 - val_accuracy: 0.8837 - val_loss: 0.3476\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.3867 - val_accuracy: 0.8953 - val_loss: 0.3269\n",
            "Epoch 46/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8775 - loss: 0.3748 - val_accuracy: 0.8837 - val_loss: 0.3325\n",
            " CNN2D Test Accuracy: 0.9011628031730652\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[129   1]\n",
            " [ 16  26]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94       130\n",
            "           1       0.96      0.62      0.75        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.93      0.81      0.85       172\n",
            "weighted avg       0.91      0.90      0.89       172\n",
            "\n",
            "\n",
            " F1 Score: 0.8931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Oversampler"
      ],
      "metadata": {
        "id": "-DfpxfQXTwDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "X_over, y_over = ros.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Befor OverSampling:\", y_train.value_counts().to_dict())\n",
        "print(\"After OverSampling:\", y_over.value_counts().to_dict())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-3rM2KoT3JI",
        "outputId": "11d3fbca-fce4-4791-f7f6-f334d172d4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Befor OverSampling: {0: 516, 1: 168}\n",
            "After OverSampling: {0: 516, 1: 516}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert integer labels (0/1) into one-hot encoded vectors for training\n",
        "y_over_cat = to_categorical(y_over, num_classes=2)\n",
        "y_test_cat = to_categorical(y_test, num_classes=2)"
      ],
      "metadata": {
        "id": "1VuM0XwKUEbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "vMrwIXa3speq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_over_lstm = X_over.reshape((X_over.shape[0], X_over.shape[1], 1))\n",
        "X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    Input(shape=(X_over_lstm.shape[1], X_over_lstm.shape[2])),\n",
        "    LSTM(64, kernel_regularizer=regularizers.l2(0.001), return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history_lstm = model_lstm.fit(\n",
        "    X_over_lstm, y_over,\n",
        "    validation_data=(X_test_lstm, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model_lstm.evaluate(X_test_lstm, y_test, verbose=0)\n",
        "print(\"LSTM (After RandomOverSampling) Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test_lstm)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\n Classification Report:{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOcE1C3tUiVo",
        "outputId": "e7b6d7b4-09f8-4c83-bca2-9592ba138847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.6139 - loss: 0.6642 - val_accuracy: 0.7326 - val_loss: 0.5191\n",
            "Epoch 2/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7262 - loss: 0.5161 - val_accuracy: 0.8314 - val_loss: 0.4685\n",
            "Epoch 3/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.4685 - val_accuracy: 0.8256 - val_loss: 0.4812\n",
            "Epoch 4/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7484 - loss: 0.5079 - val_accuracy: 0.8605 - val_loss: 0.4315\n",
            "Epoch 5/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7819 - loss: 0.4502 - val_accuracy: 0.8605 - val_loss: 0.4211\n",
            "Epoch 6/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7603 - loss: 0.4688 - val_accuracy: 0.8488 - val_loss: 0.4528\n",
            "Epoch 7/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7844 - loss: 0.4350 - val_accuracy: 0.8430 - val_loss: 0.4325\n",
            "Epoch 8/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7745 - loss: 0.4539 - val_accuracy: 0.8430 - val_loss: 0.4135\n",
            "Epoch 9/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.4861 - val_accuracy: 0.8547 - val_loss: 0.4112\n",
            "Epoch 10/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8069 - loss: 0.4058 - val_accuracy: 0.8372 - val_loss: 0.4407\n",
            "Epoch 11/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8139 - loss: 0.4181 - val_accuracy: 0.8372 - val_loss: 0.4345\n",
            "Epoch 12/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7624 - loss: 0.4505 - val_accuracy: 0.8430 - val_loss: 0.4132\n",
            "Epoch 13/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7919 - loss: 0.4267 - val_accuracy: 0.8372 - val_loss: 0.4210\n",
            "Epoch 14/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7724 - loss: 0.4496 - val_accuracy: 0.8372 - val_loss: 0.4214\n",
            "LSTM (After RandomOverSampling) Test Accuracy: 0.854651153087616\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[118  12]\n",
            " [ 13  29]]\n",
            "\n",
            " Classification Report:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.90       130\n",
            "           1       0.71      0.69      0.70        42\n",
            "\n",
            "    accuracy                           0.85       172\n",
            "   macro avg       0.80      0.80      0.80       172\n",
            "weighted avg       0.85      0.85      0.85       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN1D"
      ],
      "metadata": {
        "id": "5fQ_7YjBsrRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_over_cnn = X_over.reshape((X_over.shape[0], X_over.shape[1], 1))\n",
        "X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "model_cnn = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation=\"relu\",\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_cnn = model_cnn.fit(\n",
        "    X_over_cnn, y_over,\n",
        "    validation_data=(X_test_cnn, y_test),\n",
        "    epochs=50, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "\n",
        "loss, acc = model_cnn.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(\"CNN1D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn.predict(X_test_cnn)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\n Classification Report:{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\n F1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EydBkiqAVP6v",
        "outputId": "92524a52-d78f-49f4-a3bd-5eed985c7c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6542 - loss: 0.7181 - val_accuracy: 0.7907 - val_loss: 0.6135\n",
            "Epoch 2/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7798 - loss: 0.5593 - val_accuracy: 0.8256 - val_loss: 0.5213\n",
            "Epoch 3/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.5480 - val_accuracy: 0.8721 - val_loss: 0.4623\n",
            "Epoch 4/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.5315 - val_accuracy: 0.8779 - val_loss: 0.4557\n",
            "Epoch 5/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4899 - val_accuracy: 0.8605 - val_loss: 0.4699\n",
            "Epoch 6/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4963 - val_accuracy: 0.8547 - val_loss: 0.4639\n",
            "Epoch 7/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4771 - val_accuracy: 0.8837 - val_loss: 0.4248\n",
            "Epoch 8/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4831 - val_accuracy: 0.8663 - val_loss: 0.4362\n",
            "Epoch 9/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.4655 - val_accuracy: 0.8430 - val_loss: 0.4520\n",
            "Epoch 10/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.4528 - val_accuracy: 0.8837 - val_loss: 0.4297\n",
            "Epoch 11/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.4462 - val_accuracy: 0.8837 - val_loss: 0.4126\n",
            "Epoch 12/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.4439 - val_accuracy: 0.8430 - val_loss: 0.4609\n",
            "Epoch 13/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4373 - val_accuracy: 0.8779 - val_loss: 0.4157\n",
            "Epoch 14/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8400 - loss: 0.4245 - val_accuracy: 0.8837 - val_loss: 0.3961\n",
            "Epoch 15/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8481 - loss: 0.4259 - val_accuracy: 0.8547 - val_loss: 0.4311\n",
            "Epoch 16/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8427 - loss: 0.4052 - val_accuracy: 0.8663 - val_loss: 0.4087\n",
            "Epoch 17/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4281 - val_accuracy: 0.8547 - val_loss: 0.4064\n",
            "Epoch 18/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.4283 - val_accuracy: 0.8721 - val_loss: 0.3847\n",
            "Epoch 19/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 0.4402 - val_accuracy: 0.8837 - val_loss: 0.3998\n",
            "Epoch 20/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8459 - loss: 0.4056 - val_accuracy: 0.8605 - val_loss: 0.4060\n",
            "Epoch 21/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.4208 - val_accuracy: 0.8663 - val_loss: 0.4121\n",
            "Epoch 22/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.4208 - val_accuracy: 0.8605 - val_loss: 0.4020\n",
            "Epoch 23/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.4075 - val_accuracy: 0.8547 - val_loss: 0.4281\n",
            "CNN1D Test Accuracy: 0.8720930218696594\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[121   9]\n",
            " [ 13  29]]\n",
            "\n",
            " Classification Report:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92       130\n",
            "           1       0.76      0.69      0.72        42\n",
            "\n",
            "    accuracy                           0.87       172\n",
            "   macro avg       0.83      0.81      0.82       172\n",
            "weighted avg       0.87      0.87      0.87       172\n",
            "\n",
            "\n",
            " F1 Score: 0.8699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "ga88An8qsttT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for MLP model\n",
        "X_over_mlp = X_over\n",
        "X_test_mlp = X_test_scaled\n",
        "\n",
        "# Build the MLP model\n",
        "model_mlp = Sequential([\n",
        "    Input(shape=(X_train_mlp.shape[1],)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model (binary crossentropy + Adam optimizer)\n",
        "model_mlp.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history_mlp = model_mlp.fit(\n",
        "    X_over_mlp, y_over,\n",
        "    validation_data=(X_test_mlp, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate model performance\n",
        "loss, acc = model_mlp.evaluate(X_test_mlp, y_test, verbose=0)\n",
        "print(\"MLP Test Accuracy:\", acc)\n",
        "\n",
        "# Predict class probabilities and convert to class labels\n",
        "y_pred_probs = model_mlp.predict(X_test_mlp)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0fcxgDVVnSt",
        "outputId": "5f23547b-5312-42de-90a0-4db04fd02c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5134 - loss: 0.7203 - val_accuracy: 0.8663 - val_loss: 0.5191\n",
            "Epoch 2/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.5147 - val_accuracy: 0.8721 - val_loss: 0.4384\n",
            "Epoch 3/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4566 - val_accuracy: 0.8895 - val_loss: 0.4226\n",
            "Epoch 4/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.4393 - val_accuracy: 0.8895 - val_loss: 0.4099\n",
            "Epoch 5/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.4129 - val_accuracy: 0.8895 - val_loss: 0.3974\n",
            "Epoch 6/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7970 - loss: 0.4323 - val_accuracy: 0.9012 - val_loss: 0.3774\n",
            "Epoch 7/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.4201 - val_accuracy: 0.9012 - val_loss: 0.3607\n",
            "Epoch 8/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3799 - val_accuracy: 0.8953 - val_loss: 0.3778\n",
            "Epoch 9/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4027 - val_accuracy: 0.9012 - val_loss: 0.3599\n",
            "Epoch 10/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3738 - val_accuracy: 0.9070 - val_loss: 0.3445\n",
            "Epoch 11/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.3924 - val_accuracy: 0.9070 - val_loss: 0.3421\n",
            "Epoch 12/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3865 - val_accuracy: 0.8953 - val_loss: 0.3434\n",
            "Epoch 13/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3560 - val_accuracy: 0.8895 - val_loss: 0.3335\n",
            "Epoch 14/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.3513 - val_accuracy: 0.9128 - val_loss: 0.3483\n",
            "Epoch 15/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3580 - val_accuracy: 0.9070 - val_loss: 0.2953\n",
            "Epoch 16/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3242 - val_accuracy: 0.8953 - val_loss: 0.3296\n",
            "Epoch 17/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.3580 - val_accuracy: 0.9012 - val_loss: 0.3014\n",
            "Epoch 18/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.3477 - val_accuracy: 0.9070 - val_loss: 0.3124\n",
            "Epoch 19/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3440 - val_accuracy: 0.9186 - val_loss: 0.2985\n",
            "Epoch 20/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8473 - loss: 0.3657 - val_accuracy: 0.8837 - val_loss: 0.3082\n",
            "MLP Test Accuracy: 0.9069767594337463\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[126   4]\n",
            " [ 12  30]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       130\n",
            "           1       0.88      0.71      0.79        42\n",
            "\n",
            "    accuracy                           0.91       172\n",
            "   macro avg       0.90      0.84      0.86       172\n",
            "weighted avg       0.91      0.91      0.90       172\n",
            "\n",
            "\n",
            "F1 Score: 0.9035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "xVNg4d_vsvaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_over_cnn2d = X_over.reshape(-1, X_over.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # one-hot labels\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_over_cnn2d, y_over,\n",
        "    validation_data=(X_test_cnn2d, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "# Evaluation\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test, verbose=0)\n",
        "print(\"CNN2D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF_8-cfZWiYM",
        "outputId": "73f86d07-8165-4313-9121-c8335a37160b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5196 - loss: 0.8063 - val_accuracy: 0.8547 - val_loss: 0.6904\n",
            "Epoch 2/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.7217 - val_accuracy: 0.8140 - val_loss: 0.6194\n",
            "Epoch 3/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.6297 - val_accuracy: 0.8372 - val_loss: 0.5494\n",
            "Epoch 4/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7325 - loss: 0.6193 - val_accuracy: 0.8081 - val_loss: 0.5880\n",
            "Epoch 5/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.5803 - val_accuracy: 0.8605 - val_loss: 0.5093\n",
            "Epoch 6/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 0.5646 - val_accuracy: 0.8605 - val_loss: 0.5169\n",
            "Epoch 7/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.5683 - val_accuracy: 0.8663 - val_loss: 0.4953\n",
            "Epoch 8/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8071 - loss: 0.5321 - val_accuracy: 0.8605 - val_loss: 0.5155\n",
            "Epoch 9/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.5629 - val_accuracy: 0.8547 - val_loss: 0.5333\n",
            "Epoch 10/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.5203 - val_accuracy: 0.8721 - val_loss: 0.5079\n",
            "Epoch 11/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7614 - loss: 0.5592 - val_accuracy: 0.8721 - val_loss: 0.4826\n",
            "Epoch 12/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8203 - loss: 0.4996 - val_accuracy: 0.8779 - val_loss: 0.4705\n",
            "Epoch 13/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.5020 - val_accuracy: 0.8953 - val_loss: 0.4636\n",
            "Epoch 14/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.5267 - val_accuracy: 0.8721 - val_loss: 0.4898\n",
            "Epoch 15/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4851 - val_accuracy: 0.8895 - val_loss: 0.4673\n",
            "Epoch 16/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.5278 - val_accuracy: 0.8895 - val_loss: 0.4554\n",
            "Epoch 17/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.5063 - val_accuracy: 0.8663 - val_loss: 0.4816\n",
            "Epoch 18/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4797 - val_accuracy: 0.8895 - val_loss: 0.4522\n",
            "Epoch 19/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8263 - loss: 0.4623 - val_accuracy: 0.8721 - val_loss: 0.4934\n",
            "Epoch 20/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4797 - val_accuracy: 0.8721 - val_loss: 0.4793\n",
            "Epoch 21/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.4894 - val_accuracy: 0.8895 - val_loss: 0.4441\n",
            "Epoch 22/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.5004 - val_accuracy: 0.8895 - val_loss: 0.4192\n",
            "Epoch 23/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4862 - val_accuracy: 0.8721 - val_loss: 0.4578\n",
            "Epoch 24/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4615 - val_accuracy: 0.8837 - val_loss: 0.4356\n",
            "Epoch 25/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4609 - val_accuracy: 0.8895 - val_loss: 0.4228\n",
            "Epoch 26/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4642 - val_accuracy: 0.8895 - val_loss: 0.4029\n",
            "Epoch 27/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.4776 - val_accuracy: 0.8663 - val_loss: 0.4357\n",
            "Epoch 28/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4327 - val_accuracy: 0.8895 - val_loss: 0.4122\n",
            "Epoch 29/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4760 - val_accuracy: 0.8837 - val_loss: 0.4165\n",
            "Epoch 30/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4708 - val_accuracy: 0.8721 - val_loss: 0.4260\n",
            "Epoch 31/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.5069 - val_accuracy: 0.8837 - val_loss: 0.3990\n",
            "Epoch 32/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.4739 - val_accuracy: 0.8663 - val_loss: 0.4307\n",
            "Epoch 33/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.4505 - val_accuracy: 0.8779 - val_loss: 0.4060\n",
            "Epoch 34/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4378 - val_accuracy: 0.8837 - val_loss: 0.3922\n",
            "Epoch 35/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4597 - val_accuracy: 0.8895 - val_loss: 0.3909\n",
            "Epoch 36/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8299 - loss: 0.4363 - val_accuracy: 0.8837 - val_loss: 0.3908\n",
            "Epoch 37/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.4394 - val_accuracy: 0.8721 - val_loss: 0.3924\n",
            "Epoch 38/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4532 - val_accuracy: 0.8779 - val_loss: 0.3829\n",
            "Epoch 39/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.4337 - val_accuracy: 0.8895 - val_loss: 0.4066\n",
            "Epoch 40/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4373 - val_accuracy: 0.8779 - val_loss: 0.3752\n",
            "Epoch 41/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.4126 - val_accuracy: 0.8837 - val_loss: 0.4134\n",
            "Epoch 42/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4509 - val_accuracy: 0.8779 - val_loss: 0.3863\n",
            "Epoch 43/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8019 - loss: 0.4512 - val_accuracy: 0.8837 - val_loss: 0.3735\n",
            "Epoch 44/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.4451 - val_accuracy: 0.8721 - val_loss: 0.3930\n",
            "Epoch 45/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7979 - loss: 0.4534 - val_accuracy: 0.8779 - val_loss: 0.3740\n",
            "Epoch 46/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.4287 - val_accuracy: 0.8779 - val_loss: 0.3851\n",
            "Epoch 47/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4571 - val_accuracy: 0.8721 - val_loss: 0.3888\n",
            "Epoch 48/50\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8196 - loss: 0.4371 - val_accuracy: 0.8837 - val_loss: 0.3760\n",
            "CNN2D Test Accuracy: 0.8837209343910217\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[123   7]\n",
            " [ 13  29]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       130\n",
            "           1       0.81      0.69      0.74        42\n",
            "\n",
            "    accuracy                           0.88       172\n",
            "   macro avg       0.85      0.82      0.83       172\n",
            "weighted avg       0.88      0.88      0.88       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Undersampler"
      ],
      "metadata": {
        "id": "wrQhbhroXFaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_under, y_under = rus.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Befor UnderSampling:\", y_train.value_counts().to_dict())\n",
        "print(\"After UnderSampling:\",  y_under.value_counts().to_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhp420kwXK8j",
        "outputId": "894584cd-a0d5-4fdd-c63d-94a03d84033a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Befor UnderSampling: {0: 516, 1: 168}\n",
            "After UnderSampling: {0: 168, 1: 168}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Undersampler for MLP, LSTM, CNN1D,  CNN2D"
      ],
      "metadata": {
        "id": "eqthPrmBsx-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "X_mlp = X_under\n",
        "X_test_mlp = X_test_scaled\n",
        "\n",
        "model_mlp = Sequential([\n",
        "    Input(shape=(X_train_mlp.shape[1],)),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.0005)),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile\n",
        "model_mlp.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_mlp = model_mlp.fit(\n",
        "    X_mlp, y_under,\n",
        "    validation_data=(X_test_mlp, y_test),\n",
        "    epochs=100, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "loss, acc = model_mlp.evaluate(X_test_mlp, y_test, verbose=0)\n",
        "print(\"MLP Test Accuracy after UnderSampling:\", acc)\n",
        "\n",
        "y_pred_probs = model_mlp.predict(X_test_mlp)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "#_______________________________________________________________________________________\n",
        "# CNN1D\n",
        "X_cnn1d = X_under.reshape(-1, X_under.shape[1], 1)\n",
        "X_test_cnn1d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
        "\n",
        "model_cnn = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation=\"relu\",\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_cnn= model_cnn.fit(\n",
        "    X_cnn1d, y_under,\n",
        "    validation_data=(X_test_cnn1d, y_test),\n",
        "    epochs=50, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "loss, acc = model_cnn.evaluate(X_test_cnn1d, y_test, verbose=0)\n",
        "print(\"CNN1D Test Accuracy after UnderSampling:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn.predict(X_test_cnn1d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "#_______________________________________________________________________________________\n",
        "# CNN2D\n",
        "X_cnn2d = X_under.reshape(-1, X_under.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # one-hot labels\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_cnn2d, y_under,\n",
        "    validation_data=(X_test_cnn2d, y_test),\n",
        "    epochs=50, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test, verbose=0)\n",
        "print(\"CNN2D Test Accuracy after UnderSampling:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "#_______________________________________________________________________________________\n",
        "# LSTM\n",
        "X_lstm = X_under.reshape(-1, X_under.shape[1], 1)\n",
        "X_test_lstm = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1)\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    Input(shape=(X_over_lstm.shape[1], X_over_lstm.shape[2])),\n",
        "    LSTM(64, kernel_regularizer=regularizers.l2(0.001), return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_lstm = model_lstm.fit(\n",
        "    X_lstm, y_under,\n",
        "    validation_data=(X_test_lstm, y_test),\n",
        "    epochs=50, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")\n",
        "loss, acc = model_lstm.evaluate(X_test_lstm, y_test, verbose=0)\n",
        "print(\"LSTM Test Accuracy after UnderSampling:\", acc)\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test_lstm)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytZL1US1XsM3",
        "outputId": "70ea2f71-7ee4-4c4e-9a85-f82ec350dfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4404 - loss: 0.7825 - val_accuracy: 0.7791 - val_loss: 0.6350\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6515 - loss: 0.6649 - val_accuracy: 0.8372 - val_loss: 0.5822\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6915 - loss: 0.5978 - val_accuracy: 0.8605 - val_loss: 0.5286\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7814 - loss: 0.5436 - val_accuracy: 0.8663 - val_loss: 0.4958\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7492 - loss: 0.5109 - val_accuracy: 0.8721 - val_loss: 0.4680\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7669 - loss: 0.5123 - val_accuracy: 0.8721 - val_loss: 0.4521\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7784 - loss: 0.4962 - val_accuracy: 0.8721 - val_loss: 0.4361\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7449 - loss: 0.5126 - val_accuracy: 0.8721 - val_loss: 0.4400\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7878 - loss: 0.4790 - val_accuracy: 0.8837 - val_loss: 0.4213\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8218 - loss: 0.4331 - val_accuracy: 0.8837 - val_loss: 0.4203\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7719 - loss: 0.4935 - val_accuracy: 0.8895 - val_loss: 0.4055\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8079 - loss: 0.4691 - val_accuracy: 0.9012 - val_loss: 0.4065\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8102 - loss: 0.4640 - val_accuracy: 0.9012 - val_loss: 0.4012\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8047 - loss: 0.4727 - val_accuracy: 0.8953 - val_loss: 0.3920\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7814 - loss: 0.4999 - val_accuracy: 0.9012 - val_loss: 0.3924\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7703 - loss: 0.4497 - val_accuracy: 0.8953 - val_loss: 0.3903\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7828 - loss: 0.4539 - val_accuracy: 0.8953 - val_loss: 0.3928\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - loss: 0.4416 - val_accuracy: 0.9012 - val_loss: 0.3776\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4145 - val_accuracy: 0.8953 - val_loss: 0.3817\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4473 - val_accuracy: 0.8953 - val_loss: 0.3720\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7841 - loss: 0.4556 - val_accuracy: 0.8895 - val_loss: 0.3724\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.4118 - val_accuracy: 0.8895 - val_loss: 0.3785\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.4107 - val_accuracy: 0.8895 - val_loss: 0.3750\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 0.4310 - val_accuracy: 0.8895 - val_loss: 0.3795\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8275 - loss: 0.4278 - val_accuracy: 0.9012 - val_loss: 0.3618\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8361 - loss: 0.3959 - val_accuracy: 0.8953 - val_loss: 0.3652\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.3845 - val_accuracy: 0.8953 - val_loss: 0.3680\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8440 - loss: 0.3995 - val_accuracy: 0.8953 - val_loss: 0.3635\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4211 - val_accuracy: 0.8895 - val_loss: 0.3687\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4188 - val_accuracy: 0.9012 - val_loss: 0.3677\n",
            "MLP Test Accuracy after UnderSampling: 0.9011628031730652\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[126   4]\n",
            " [ 13  29]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94       130\n",
            "           1       0.88      0.69      0.77        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.89      0.83      0.86       172\n",
            "weighted avg       0.90      0.90      0.90       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8969\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6279 - loss: 0.7535 - val_accuracy: 0.8721 - val_loss: 0.6101\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7256 - loss: 0.6475 - val_accuracy: 0.8779 - val_loss: 0.5347\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7917 - loss: 0.5882 - val_accuracy: 0.8721 - val_loss: 0.5180\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7571 - loss: 0.5950 - val_accuracy: 0.8605 - val_loss: 0.5156\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 0.6236 - val_accuracy: 0.8779 - val_loss: 0.5042\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7468 - loss: 0.5953 - val_accuracy: 0.8721 - val_loss: 0.4811\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7462 - loss: 0.5991 - val_accuracy: 0.8779 - val_loss: 0.4676\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5594 - val_accuracy: 0.8837 - val_loss: 0.4810\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7750 - loss: 0.5380 - val_accuracy: 0.8779 - val_loss: 0.4862\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 0.4946 - val_accuracy: 0.8837 - val_loss: 0.4717\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7909 - loss: 0.5129 - val_accuracy: 0.8779 - val_loss: 0.4752\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7900 - loss: 0.5224 - val_accuracy: 0.8721 - val_loss: 0.4652\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8145 - loss: 0.4954 - val_accuracy: 0.8837 - val_loss: 0.4667\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.5426 - val_accuracy: 0.8837 - val_loss: 0.4530\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 0.5277 - val_accuracy: 0.8895 - val_loss: 0.4373\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7393 - loss: 0.5658 - val_accuracy: 0.8837 - val_loss: 0.4498\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.5085 - val_accuracy: 0.8895 - val_loss: 0.4308\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.5325 - val_accuracy: 0.8779 - val_loss: 0.4429\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8334 - loss: 0.4668 - val_accuracy: 0.8605 - val_loss: 0.4573\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8290 - loss: 0.4710 - val_accuracy: 0.8721 - val_loss: 0.4513\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8015 - loss: 0.4661 - val_accuracy: 0.8895 - val_loss: 0.4196\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7812 - loss: 0.5130 - val_accuracy: 0.8837 - val_loss: 0.4253\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8471 - loss: 0.4469 - val_accuracy: 0.8837 - val_loss: 0.4243\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7785 - loss: 0.4783 - val_accuracy: 0.8779 - val_loss: 0.4182\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7791 - loss: 0.4920 - val_accuracy: 0.8663 - val_loss: 0.4363\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8176 - loss: 0.5000 - val_accuracy: 0.8779 - val_loss: 0.4086\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.4700 - val_accuracy: 0.8953 - val_loss: 0.4096\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8073 - loss: 0.4702 - val_accuracy: 0.8953 - val_loss: 0.4085\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8300 - loss: 0.4748 - val_accuracy: 0.8663 - val_loss: 0.4443\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8291 - loss: 0.5011 - val_accuracy: 0.8895 - val_loss: 0.4057\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8094 - loss: 0.4551 - val_accuracy: 0.8605 - val_loss: 0.4436\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7849 - loss: 0.4772 - val_accuracy: 0.8837 - val_loss: 0.3995\n",
            "Epoch 33/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8444 - loss: 0.4366 - val_accuracy: 0.8721 - val_loss: 0.4026\n",
            "Epoch 34/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7780 - loss: 0.5223 - val_accuracy: 0.8547 - val_loss: 0.4144\n",
            "Epoch 35/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.4778 - val_accuracy: 0.8779 - val_loss: 0.4029\n",
            "Epoch 36/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.4843 - val_accuracy: 0.8663 - val_loss: 0.4036\n",
            "Epoch 37/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7961 - loss: 0.4679 - val_accuracy: 0.8547 - val_loss: 0.4207\n",
            "CNN1D Test Accuracy after UnderSampling: 0.8837209343910217\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[124   6]\n",
            " [ 14  28]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93       130\n",
            "           1       0.82      0.67      0.74        42\n",
            "\n",
            "    accuracy                           0.88       172\n",
            "   macro avg       0.86      0.81      0.83       172\n",
            "weighted avg       0.88      0.88      0.88       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8793\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4784 - loss: 0.8080 - val_accuracy: 0.8198 - val_loss: 0.7601\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5589 - loss: 0.8004 - val_accuracy: 0.6628 - val_loss: 0.7597\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5960 - loss: 0.7604 - val_accuracy: 0.6395 - val_loss: 0.7465\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6678 - loss: 0.7133 - val_accuracy: 0.7616 - val_loss: 0.6826\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7223 - loss: 0.6972 - val_accuracy: 0.8023 - val_loss: 0.6233\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6738 - loss: 0.6990 - val_accuracy: 0.7733 - val_loss: 0.6227\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7030 - loss: 0.6480 - val_accuracy: 0.8081 - val_loss: 0.5640\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7227 - loss: 0.6376 - val_accuracy: 0.8023 - val_loss: 0.5681\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6890 - loss: 0.6658 - val_accuracy: 0.8198 - val_loss: 0.5262\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7374 - loss: 0.6534 - val_accuracy: 0.8198 - val_loss: 0.5302\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7124 - loss: 0.6698 - val_accuracy: 0.8140 - val_loss: 0.5793\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.6429 - val_accuracy: 0.8314 - val_loss: 0.5450\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7451 - loss: 0.6246 - val_accuracy: 0.8605 - val_loss: 0.5155\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7010 - loss: 0.6340 - val_accuracy: 0.8547 - val_loss: 0.5228\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8009 - loss: 0.5803 - val_accuracy: 0.8430 - val_loss: 0.5340\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7267 - loss: 0.6192 - val_accuracy: 0.8430 - val_loss: 0.5238\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7265 - loss: 0.6019 - val_accuracy: 0.8488 - val_loss: 0.5185\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.5959 - val_accuracy: 0.8488 - val_loss: 0.5066\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7513 - loss: 0.5721 - val_accuracy: 0.8430 - val_loss: 0.5087\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7561 - loss: 0.5826 - val_accuracy: 0.8372 - val_loss: 0.5184\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.5934 - val_accuracy: 0.8430 - val_loss: 0.5236\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7426 - loss: 0.5685 - val_accuracy: 0.8547 - val_loss: 0.5235\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7621 - loss: 0.5419 - val_accuracy: 0.8721 - val_loss: 0.4952\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7088 - loss: 0.6058 - val_accuracy: 0.8837 - val_loss: 0.4936\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8119 - loss: 0.5068 - val_accuracy: 0.8605 - val_loss: 0.5048\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7972 - loss: 0.5124 - val_accuracy: 0.8837 - val_loss: 0.4803\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7629 - loss: 0.5536 - val_accuracy: 0.8779 - val_loss: 0.4744\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7711 - loss: 0.5518 - val_accuracy: 0.8663 - val_loss: 0.4999\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6845 - loss: 0.5904 - val_accuracy: 0.8895 - val_loss: 0.4925\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7996 - loss: 0.5265 - val_accuracy: 0.8837 - val_loss: 0.4805\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.5273 - val_accuracy: 0.8605 - val_loss: 0.4955\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 0.5725 - val_accuracy: 0.8663 - val_loss: 0.4998\n",
            "CNN2D Test Accuracy after UnderSampling: 0.8779069781303406\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[123   7]\n",
            " [ 14  28]]\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       130\n",
            "           1       0.80      0.67      0.73        42\n",
            "\n",
            "    accuracy                           0.88       172\n",
            "   macro avg       0.85      0.81      0.82       172\n",
            "weighted avg       0.87      0.88      0.87       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8740\n",
            "Epoch 1/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5467 - loss: 0.6857 - val_accuracy: 0.7616 - val_loss: 0.6467\n",
            "Epoch 2/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6172 - loss: 0.6581 - val_accuracy: 0.7849 - val_loss: 0.6098\n",
            "Epoch 3/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7057 - loss: 0.6039 - val_accuracy: 0.7733 - val_loss: 0.5347\n",
            "Epoch 4/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7632 - loss: 0.5091 - val_accuracy: 0.7907 - val_loss: 0.4980\n",
            "Epoch 5/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7649 - loss: 0.4867 - val_accuracy: 0.8488 - val_loss: 0.4717\n",
            "Epoch 6/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7576 - loss: 0.4805 - val_accuracy: 0.8488 - val_loss: 0.4615\n",
            "Epoch 7/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7151 - loss: 0.5136 - val_accuracy: 0.8372 - val_loss: 0.4715\n",
            "Epoch 8/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7189 - loss: 0.5515 - val_accuracy: 0.8430 - val_loss: 0.4568\n",
            "Epoch 9/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7662 - loss: 0.4821 - val_accuracy: 0.8430 - val_loss: 0.4520\n",
            "Epoch 10/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7493 - loss: 0.5223 - val_accuracy: 0.8488 - val_loss: 0.4509\n",
            "Epoch 11/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7377 - loss: 0.4886 - val_accuracy: 0.8488 - val_loss: 0.4505\n",
            "Epoch 12/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7578 - loss: 0.4709 - val_accuracy: 0.8430 - val_loss: 0.4406\n",
            "Epoch 13/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7617 - loss: 0.4684 - val_accuracy: 0.8488 - val_loss: 0.4404\n",
            "Epoch 14/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7581 - loss: 0.4655 - val_accuracy: 0.8488 - val_loss: 0.4412\n",
            "Epoch 15/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7455 - loss: 0.4743 - val_accuracy: 0.8372 - val_loss: 0.4556\n",
            "Epoch 16/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7721 - loss: 0.4961 - val_accuracy: 0.8547 - val_loss: 0.4378\n",
            "Epoch 17/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7483 - loss: 0.5085 - val_accuracy: 0.8430 - val_loss: 0.4433\n",
            "Epoch 18/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8091 - loss: 0.4329 - val_accuracy: 0.8372 - val_loss: 0.4467\n",
            "Epoch 19/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7447 - loss: 0.5118 - val_accuracy: 0.8488 - val_loss: 0.4371\n",
            "Epoch 20/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7281 - loss: 0.5233 - val_accuracy: 0.8430 - val_loss: 0.4469\n",
            "Epoch 21/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7350 - loss: 0.5328 - val_accuracy: 0.8488 - val_loss: 0.4382\n",
            "Epoch 22/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7910 - loss: 0.4612 - val_accuracy: 0.8547 - val_loss: 0.4377\n",
            "Epoch 23/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7585 - loss: 0.4605 - val_accuracy: 0.8488 - val_loss: 0.4326\n",
            "Epoch 24/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7807 - loss: 0.5064 - val_accuracy: 0.8547 - val_loss: 0.4319\n",
            "Epoch 25/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.4890 - val_accuracy: 0.8430 - val_loss: 0.4451\n",
            "Epoch 26/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7801 - loss: 0.4853 - val_accuracy: 0.8488 - val_loss: 0.4315\n",
            "Epoch 27/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7670 - loss: 0.4798 - val_accuracy: 0.8605 - val_loss: 0.4298\n",
            "Epoch 28/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7777 - loss: 0.4841 - val_accuracy: 0.8488 - val_loss: 0.4357\n",
            "Epoch 29/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7478 - loss: 0.4865 - val_accuracy: 0.8488 - val_loss: 0.4380\n",
            "Epoch 30/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7387 - loss: 0.4987 - val_accuracy: 0.8488 - val_loss: 0.4247\n",
            "Epoch 31/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7534 - loss: 0.4902 - val_accuracy: 0.8372 - val_loss: 0.4335\n",
            "Epoch 32/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7807 - loss: 0.4416 - val_accuracy: 0.8547 - val_loss: 0.4234\n",
            "Epoch 33/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7232 - loss: 0.5142 - val_accuracy: 0.8488 - val_loss: 0.4329\n",
            "Epoch 34/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7373 - loss: 0.4628 - val_accuracy: 0.8488 - val_loss: 0.4249\n",
            "Epoch 35/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7803 - loss: 0.4535 - val_accuracy: 0.8547 - val_loss: 0.4273\n",
            "Epoch 36/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7923 - loss: 0.4516 - val_accuracy: 0.8488 - val_loss: 0.4247\n",
            "Epoch 37/50\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7723 - loss: 0.4872 - val_accuracy: 0.8547 - val_loss: 0.4269\n",
            "LSTM Test Accuracy after UnderSampling: 0.854651153087616\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[120  10]\n",
            " [ 15  27]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91       130\n",
            "           1       0.73      0.64      0.68        42\n",
            "\n",
            "    accuracy                           0.85       172\n",
            "   macro avg       0.81      0.78      0.79       172\n",
            "weighted avg       0.85      0.85      0.85       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conditional Tabular GAN"
      ],
      "metadata": {
        "id": "hpBYtUwKd5jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfgan = df.copy()\n",
        "dfgan['Classes'] = dfgan['Classes'].astype(str)\n",
        "\n",
        "print(\"Shape:\", dfgan.shape)\n",
        "print(dfgan['Classes'].value_counts())\n",
        "dfgan.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yvUt7v1rgs6K",
        "outputId": "30180bad-f4d2-42ff-ab17-f3bfb62814de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (856, 14)\n",
            "Classes\n",
            "0    646\n",
            "1    210\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   day  month  year  Temperature  RH    Ws  Rain  FFMC  DMC    DC  ISI  BUI  \\\n",
              "0    1      6  2012         29.0  57  18.0   0.0  65.7  3.4   7.6  1.3  3.4   \n",
              "1    2      6  2012         29.0  61  13.0   1.3  64.4  4.1   7.6  1.0  3.9   \n",
              "2    3      6  2012         26.0  82  22.0  13.1  47.1  2.5   7.1  0.3  2.7   \n",
              "3    4      6  2012         25.0  89  13.0   2.5  28.6  1.3   6.9  0.0  1.7   \n",
              "4    5      6  2012         27.0  77  16.0   0.0  64.8  3.0  14.2  1.2  3.9   \n",
              "\n",
              "   FWI Classes  \n",
              "0  0.5       0  \n",
              "1  0.4       0  \n",
              "2  0.1       0  \n",
              "3  0.0       0  \n",
              "4  0.5       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d074f10a-e95d-4de3-a6ae-c86b3b062d61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>RH</th>\n",
              "      <th>Ws</th>\n",
              "      <th>Rain</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>BUI</th>\n",
              "      <th>FWI</th>\n",
              "      <th>Classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>29.0</td>\n",
              "      <td>57</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>7.6</td>\n",
              "      <td>1.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>29.0</td>\n",
              "      <td>61</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>64.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>26.0</td>\n",
              "      <td>82</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>47.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>25.0</td>\n",
              "      <td>89</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>28.6</td>\n",
              "      <td>1.3</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>27.0</td>\n",
              "      <td>77</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d074f10a-e95d-4de3-a6ae-c86b3b062d61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d074f10a-e95d-4de3-a6ae-c86b3b062d61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d074f10a-e95d-4de3-a6ae-c86b3b062d61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-529ef350-7763-4839-bbf4-18c6e3fa531c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-529ef350-7763-4839-bbf4-18c6e3fa531c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-529ef350-7763-4839-bbf4-18c6e3fa531c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dfgan",
              "summary": "{\n  \"name\": \"dfgan\",\n  \"rows\": 856,\n  \"fields\": [\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          28,\n          16,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3,\n          10,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2012,\n        \"max\": 2025,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2025,\n          2018,\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.955278504341578,\n        \"min\": 12.0,\n        \"max\": 45.0,\n        \"num_unique_values\": 237,\n        \"samples\": [\n          33.6,\n          38.0,\n          15.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 14,\n        \"max\": 100,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          45,\n          57,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ws\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.798693680604626,\n        \"min\": 6.0,\n        \"max\": 48.5,\n        \"num_unique_values\": 250,\n        \"samples\": [\n          24.3,\n          12.0,\n          32.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2183004043667227,\n        \"min\": 0.0,\n        \"max\": 16.8,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          1.5,\n          4.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FFMC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.212057754232557,\n        \"min\": 28.6,\n        \"max\": 97.6602,\n        \"num_unique_values\": 709,\n        \"samples\": [\n          91.0605,\n          95.0817,\n          86.597\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DMC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.395977501107377,\n        \"min\": 0.7,\n        \"max\": 65.9,\n        \"num_unique_values\": 754,\n        \"samples\": [\n          7.2847,\n          7.0696,\n          9.017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.21931200102624,\n        \"min\": 6.9,\n        \"max\": 220.4,\n        \"num_unique_values\": 663,\n        \"samples\": [\n          24.052,\n          25.27,\n          19.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ISI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2584.3429351558193,\n        \"min\": 0.0,\n        \"max\": 34908.0673,\n        \"num_unique_values\": 702,\n        \"samples\": [\n          69.0549,\n          135.8381,\n          8.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BUI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.50539406386682,\n        \"min\": 1.1,\n        \"max\": 68.0,\n        \"num_unique_values\": 772,\n        \"samples\": [\n          7.2434,\n          11.9193,\n          10.4878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FWI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 128.17478915015215,\n        \"min\": 0.0,\n        \"max\": 1222.2009,\n        \"num_unique_values\": 730,\n        \"samples\": [\n          134.1881,\n          346.2553,\n          41.0912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Classes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metadata object for single table\n",
        "metadata = SingleTableMetadata()\n",
        "\n",
        "# Automatically detect schema from the real dataframe\n",
        "metadata.detect_from_dataframe(data=dfgan)\n",
        "\n",
        "# Initialize CTGAN synthesizer with the detected metadata\n",
        "ctgan = CTGANSynthesizer(metadata)\n",
        "\n",
        "# Train CTGAN on the real data\n",
        "ctgan.fit(dfgan)\n",
        "\n",
        "# Generate 500 synthetic samples\n",
        "synthetic_data = ctgan.sample(num_rows=500)\n",
        "\n",
        "# Display the first few rows, shape, and class distribution\n",
        "print(synthetic_data.head())\n",
        "print(\"Shape:\", synthetic_data.shape)\n",
        "print(synthetic_data['Classes'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuX91yYTgY2A",
        "outputId": "649b3758-2bd9-46cf-9a97-769abae41708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sdv/single_table/base.py:168: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
            "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/sdv/single_table/base.py:134: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/ctgan/synthesizers/_utils.py:16: FutureWarning: `cuda` parameter is deprecated and will be removed in a future release. Please use `enable_gpu` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   day  month  year  Temperature   RH    Ws  Rain     FFMC      DMC      DC  \\\n",
            "0   30     12  2012         19.6  100  23.5   0.0  94.4517   3.2470  18.636   \n",
            "1   31      9  2021         32.7   87  13.7   0.0  91.6659  10.3420  27.936   \n",
            "2   12      9  2012         41.5   60  22.7   0.0  82.0662   4.3005  48.077   \n",
            "3   30      8  2012         31.9   64  14.0   0.0  88.7278  18.7792  23.664   \n",
            "4    6      7  2018         43.1   89  14.8   0.1  87.2189   7.1182  16.750   \n",
            "\n",
            "        ISI     BUI       FWI Classes  \n",
            "0  365.3910  9.0594    8.5099       0  \n",
            "1    0.0000  5.9536  253.8418       0  \n",
            "2  457.9593  6.3540   45.9713       0  \n",
            "3    0.0000  4.6366   27.7148       0  \n",
            "4  170.1749  6.3819    0.0000       0  \n",
            "Shape: (500, 14)\n",
            "Classes\n",
            "0    346\n",
            "1    154\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine original and synthetic data\n"
      ],
      "metadata": {
        "id": "wfjftV8qB647"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_augmented = pd.concat([dfgan, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Check the new shape and class distribution\n",
        "print(\"New shape:\", df_augmented.shape)\n",
        "print(df_augmented['Classes'].value_counts())\n",
        "\n",
        "# Save the augmented dataset to a CSV file\n",
        "df_augmented.to_csv(\"merged_fire_data_with_gan.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6as8LmXh4O4",
        "outputId": "878261f4-e30d-4f3e-b990-8837fdeb58ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape: (1356, 14)\n",
            "Classes\n",
            "0    992\n",
            "1    364\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features & target\n",
        "X = df_augmented.drop(\"Classes\", axis=1)\n",
        "y = df_augmented[\"Classes\"]\n",
        "\n",
        "# Split train/test first\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Then encode labels\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n"
      ],
      "metadata": {
        "id": "ZmU5sKz52h7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Random Forest\n"
      ],
      "metadata": {
        "id": "Ju2-B5OgB-MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid_rf = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 5],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Random Forest Best params:\", grid_rf.best_params_)\n",
        "print(\"Random Forest Best CV Accuracy:\", grid_rf.best_score_)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "cv_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores_rf)\n",
        "print(\"Mean CV:\", cv_scores_rf.mean())\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "f1_fire = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl-TO7nDioba",
        "outputId": "31ae54d9-8aac-4200-ec2e-4d7461914429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Best params: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Random Forest Best CV Accuracy: 0.8468552654036525\n",
            "CV Scores: [0.83870968 0.84792627 0.84792627 0.86175115 0.83796296]\n",
            "Mean CV: 0.8468552654036525\n",
            "Test Accuracy: 0.8198529411764706\n",
            "Overall F1 Score: 0.7931\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.81      0.98      0.89       199\n",
            "        fire       0.88      0.38      0.53        73\n",
            "\n",
            "    accuracy                           0.82       272\n",
            "   macro avg       0.84      0.68      0.71       272\n",
            "weighted avg       0.83      0.82      0.79       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "s7X1MipBCFec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
        "\n",
        "param_grid_xgb = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"XGBoost Best params:\", grid_xgb.best_params_)\n",
        "print(\"XGBoost Best CV Accuracy:\", grid_xgb.best_score_)\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "cv_scores_xgb = cross_val_score(best_xgb, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores_xgb)\n",
        "print(\"Mean CV:\", cv_scores_xgb.mean())\n",
        "\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "f1_fire = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zjs26Axi0QU",
        "outputId": "6e569f43-a7b9-40c9-dd52-ec2144b59c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.8}\n",
            "XGBoost Best CV Accuracy: 0.8496245093019287\n",
            "CV Scores: [0.86635945 0.85253456 0.84792627 0.83870968 0.84259259]\n",
            "Mean CV: 0.8496245093019287\n",
            "Test Accuracy: 0.8566176470588235\n",
            "Overall F1 Score: 0.8510\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.87      0.94      0.91       199\n",
            "        fire       0.79      0.63      0.70        73\n",
            "\n",
            "    accuracy                           0.86       272\n",
            "   macro avg       0.83      0.78      0.80       272\n",
            "weighted avg       0.85      0.86      0.85       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "jUTzLMroCIbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "# Grid Search parameters\n",
        "param_grid_cat = {\n",
        "    \"iterations\": [200, 400],\n",
        "    \"depth\": [4, 6, 8],\n",
        "    \"learning_rate\": [0.01, 0.1],\n",
        "    \"l2_leaf_reg\": [1, 3, 5]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_cat = GridSearchCV(cat, param_grid_cat, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_cat.fit(X_train, y_train)\n",
        "\n",
        "print(\" CatBoost Best params:\", grid_cat.best_params_)\n",
        "print(\" CatBoost Best CV Accuracy:\", grid_cat.best_score_)\n",
        "\n",
        "# Cross-validation explicitly\n",
        "best_cat = grid_cat.best_estimator_\n",
        "cv_scores = cross_val_score(best_cat, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "# Test evaluation\n",
        "y_pred_cat = best_cat.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_cat))\n",
        "f1_fire = f1_score(y_test, y_pred_cat, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWTQVpGqi91B",
        "outputId": "c80d3c62-6088-4d3d-ebd3-4ce4406c539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CatBoost Best params: {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
            " CatBoost Best CV Accuracy: 0.84778972520908\n",
            "CV Scores: [0.83410138 0.87096774 0.83410138 0.84792627 0.85185185]\n",
            "Mean CV: 0.84778972520908\n",
            "Test Accuracy: 0.8602941176470589\n",
            "Overall F1 Score: 0.8553\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91       199\n",
            "           1       0.80      0.64      0.71        73\n",
            "\n",
            "    accuracy                           0.86       272\n",
            "   macro avg       0.84      0.79      0.81       272\n",
            "weighted avg       0.86      0.86      0.86       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking Classifier\n"
      ],
      "metadata": {
        "id": "6baQVRANCM9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_params = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [None, 10, 20]\n",
        "}\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "rf_grid.fit(X_train, y_train)\n",
        "print(\"Best RF Params:\", rf_grid.best_params_)\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "xgb_pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", xgb)\n",
        "])\n",
        "xgb_params = {\n",
        "    \"clf__n_estimators\": [100, 200],\n",
        "    \"clf__max_depth\": [3, 5, 7],\n",
        "    \"clf__learning_rate\": [0.01, 0.1]\n",
        "}\n",
        "xgb_grid = GridSearchCV(xgb_pipe, xgb_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "print(\"Best XGB Params:\", xgb_grid.best_params_)\n",
        "\n",
        "cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "cat_params = {\n",
        "    \"iterations\": [200, 500],\n",
        "    \"depth\": [4, 6, 8],\n",
        "    \"learning_rate\": [0.01, 0.1]\n",
        "}\n",
        "cat_grid = GridSearchCV(cat, cat_params, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "cat_grid.fit(X_train, y_train)\n",
        "print(\"Best Cat Params:\", cat_grid.best_params_)\n",
        "\n",
        "# Stacking Classifier\n",
        "estimators = [\n",
        "    (\"rf\", rf_grid.best_estimator_),\n",
        "    (\"xgb\", xgb_grid.best_estimator_),\n",
        "    (\"cat\", cat_grid.best_estimator_)\n",
        "]\n",
        "# Create a stacking ensemble with Logistic Regression as the meta-model\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "scores = cross_val_score(stack_model, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
        "print(\"Stacking CV Accuracy: %.4f ± %.4f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_stack = stack_model.predict(X_test)\n",
        "print(\"Stacking Test Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
        "f1_fire = f1_score(y_test, y_pred_stack, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_stack))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdwxZOwk9TdL",
        "outputId": "6cfdddea-d246-4067-c27a-bfa825af3633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RF Params: {'max_depth': 20, 'n_estimators': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [20:53:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGB Params: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 200}\n",
            "Best Cat Params: {'depth': 8, 'iterations': 200, 'learning_rate': 0.1}\n",
            "Stacking CV Accuracy: 0.8533 ± 0.0182\n",
            "Stacking Test Accuracy: 0.8382352941176471\n",
            "Overall F1 Score: 0.8293\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       199\n",
            "           1       0.77      0.56      0.65        73\n",
            "\n",
            "    accuracy                           0.84       272\n",
            "   macro avg       0.81      0.75      0.77       272\n",
            "weighted avg       0.83      0.84      0.83       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# one-hot for CNN\n",
        "y_train_cat = to_categorical(y_train, num_classes=2)\n",
        "y_test_cat = to_categorical(y_test, num_classes=2)\n"
      ],
      "metadata": {
        "id": "TK84ObVz-C6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "2eybq2CS-BF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cnn2d = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "#Bulid model\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_train_cnn2d, y_train_cat,\n",
        "    validation_data=(X_test_cnn2d, y_test_cat),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test_cat, verbose=0)\n",
        "print(\"CNN2D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\n Confusion Matrix:\\n {cm}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CotY-u1_-GbM",
        "outputId": "9e9a2183-217a-4028-fa5a-3c988e25f077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.6806 - loss: 0.7620 - val_accuracy: 0.7316 - val_loss: 0.6750\n",
            "Epoch 2/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7055 - loss: 0.7128 - val_accuracy: 0.7353 - val_loss: 0.6403\n",
            "Epoch 3/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7257 - loss: 0.6539 - val_accuracy: 0.7610 - val_loss: 0.6198\n",
            "Epoch 4/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7538 - loss: 0.6386 - val_accuracy: 0.7831 - val_loss: 0.6007\n",
            "Epoch 5/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7735 - loss: 0.6302 - val_accuracy: 0.7941 - val_loss: 0.5895\n",
            "Epoch 6/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7558 - loss: 0.6058 - val_accuracy: 0.7794 - val_loss: 0.5870\n",
            "Epoch 7/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7835 - loss: 0.5700 - val_accuracy: 0.7794 - val_loss: 0.5784\n",
            "Epoch 8/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7858 - loss: 0.5973 - val_accuracy: 0.7868 - val_loss: 0.5771\n",
            "Epoch 9/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7786 - loss: 0.5856 - val_accuracy: 0.7794 - val_loss: 0.5686\n",
            "Epoch 10/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7576 - loss: 0.5767 - val_accuracy: 0.7904 - val_loss: 0.5647\n",
            "Epoch 11/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7734 - loss: 0.5786 - val_accuracy: 0.7904 - val_loss: 0.5600\n",
            "Epoch 12/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7903 - loss: 0.5587 - val_accuracy: 0.7941 - val_loss: 0.5546\n",
            "Epoch 13/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7894 - loss: 0.5732 - val_accuracy: 0.7794 - val_loss: 0.5541\n",
            "Epoch 14/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7703 - loss: 0.5748 - val_accuracy: 0.7978 - val_loss: 0.5487\n",
            "Epoch 15/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7654 - loss: 0.5502 - val_accuracy: 0.7831 - val_loss: 0.5503\n",
            "Epoch 16/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.5457 - val_accuracy: 0.8051 - val_loss: 0.5411\n",
            "Epoch 17/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7725 - loss: 0.5562 - val_accuracy: 0.8015 - val_loss: 0.5365\n",
            "Epoch 18/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.5439 - val_accuracy: 0.8051 - val_loss: 0.5322\n",
            "Epoch 19/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.5455 - val_accuracy: 0.8015 - val_loss: 0.5319\n",
            "Epoch 20/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.5443 - val_accuracy: 0.7868 - val_loss: 0.5308\n",
            "Epoch 21/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7861 - loss: 0.5445 - val_accuracy: 0.8051 - val_loss: 0.5235\n",
            "Epoch 22/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.4884 - val_accuracy: 0.8051 - val_loss: 0.5213\n",
            "Epoch 23/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.5326 - val_accuracy: 0.8088 - val_loss: 0.5185\n",
            "Epoch 24/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.5227 - val_accuracy: 0.7868 - val_loss: 0.5235\n",
            "Epoch 25/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.5080 - val_accuracy: 0.8051 - val_loss: 0.5140\n",
            "Epoch 26/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.5121 - val_accuracy: 0.7978 - val_loss: 0.5154\n",
            "Epoch 27/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.5057 - val_accuracy: 0.8088 - val_loss: 0.5084\n",
            "Epoch 28/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7571 - loss: 0.5723 - val_accuracy: 0.7941 - val_loss: 0.5117\n",
            "Epoch 29/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7972 - loss: 0.5005 - val_accuracy: 0.8051 - val_loss: 0.5061\n",
            "Epoch 30/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7965 - loss: 0.5145 - val_accuracy: 0.8199 - val_loss: 0.5014\n",
            "Epoch 31/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.5123 - val_accuracy: 0.7941 - val_loss: 0.5084\n",
            "Epoch 32/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.5205 - val_accuracy: 0.8015 - val_loss: 0.4996\n",
            "Epoch 33/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8006 - loss: 0.5013 - val_accuracy: 0.7941 - val_loss: 0.5037\n",
            "Epoch 34/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7965 - loss: 0.5331 - val_accuracy: 0.8051 - val_loss: 0.4960\n",
            "Epoch 35/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - loss: 0.5005 - val_accuracy: 0.8015 - val_loss: 0.4994\n",
            "Epoch 36/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7991 - loss: 0.5142 - val_accuracy: 0.7978 - val_loss: 0.5009\n",
            "Epoch 37/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8079 - loss: 0.4794 - val_accuracy: 0.7978 - val_loss: 0.4917\n",
            "Epoch 38/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8036 - loss: 0.5010 - val_accuracy: 0.7978 - val_loss: 0.4948\n",
            "Epoch 39/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8225 - loss: 0.4768 - val_accuracy: 0.8125 - val_loss: 0.4886\n",
            "Epoch 40/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7911 - loss: 0.4985 - val_accuracy: 0.8125 - val_loss: 0.4840\n",
            "Epoch 41/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8034 - loss: 0.5146 - val_accuracy: 0.8235 - val_loss: 0.4861\n",
            "Epoch 42/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8046 - loss: 0.4804 - val_accuracy: 0.8199 - val_loss: 0.4846\n",
            "Epoch 43/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7890 - loss: 0.4905 - val_accuracy: 0.8051 - val_loss: 0.4847\n",
            "Epoch 44/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7965 - loss: 0.5201 - val_accuracy: 0.8051 - val_loss: 0.4846\n",
            "Epoch 45/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7837 - loss: 0.5050 - val_accuracy: 0.8162 - val_loss: 0.4827\n",
            "Epoch 46/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8247 - loss: 0.4780 - val_accuracy: 0.8125 - val_loss: 0.4828\n",
            "Epoch 47/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.4785 - val_accuracy: 0.8088 - val_loss: 0.4826\n",
            "Epoch 48/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.4722 - val_accuracy: 0.8051 - val_loss: 0.4805\n",
            "Epoch 49/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8155 - loss: 0.4752 - val_accuracy: 0.8051 - val_loss: 0.4803\n",
            "Epoch 50/50\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7947 - loss: 0.4928 - val_accuracy: 0.8125 - val_loss: 0.4800\n",
            "CNN2D Test Accuracy: 0.8125\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\n",
            " Confusion Matrix:\n",
            " [[195   4]\n",
            " [ 47  26]]\n",
            "\n",
            "F1 Score: 0.7825\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.98      0.88       199\n",
            "           1       0.87      0.36      0.50        73\n",
            "\n",
            "    accuracy                           0.81       272\n",
            "   macro avg       0.84      0.67      0.69       272\n",
            "weighted avg       0.82      0.81      0.78       272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection"
      ],
      "metadata": {
        "id": "uC1rNmDCw7n3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##L1"
      ],
      "metadata": {
        "id": "_OlLF93BzJ-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/merged_fire_data_cleaned.csv\")\n",
        "\n",
        "X = df.drop(\"Classes\", axis=1)\n",
        "y = df[\"Classes\"]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "for C in [0.001, 0.01, 0.1, 1]:\n",
        "    lsvc = LinearSVC(C=C, penalty='l1', dual=False, max_iter=5000, random_state=42)\n",
        "    lsvc.fit(X_scaled, y)\n",
        "    model = SelectFromModel(lsvc, prefit=True)\n",
        "    print(f\"C={C} → {sum(model.get_support())} features selected\")\n",
        "\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=5000, random_state=42)\n",
        "lsvc.fit(X_scaled, y)\n",
        "\n",
        "model = SelectFromModel(lsvc, prefit=True)\n",
        "X_new = model.transform(X_scaled)\n",
        "\n",
        "print(\"Original shape:\", X.shape)\n",
        "print(\"Reduced shape:\", X_new.shape)\n",
        "\n",
        "selected_features = X.columns[model.get_support()]\n",
        "print(\"Selected features:\")\n",
        "print(selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "f4YN5WbIxFc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353390fb-13cd-44f3-c320-b3e416d800fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.001 → 0 features selected\n",
            "C=0.01 → 5 features selected\n",
            "C=0.1 → 10 features selected\n",
            "C=1 → 13 features selected\n",
            "Original shape: (856, 13)\n",
            "Reduced shape: (856, 5)\n",
            "Selected features:\n",
            "['year', 'Ws', 'FFMC', 'BUI', 'FWI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected features after L1 selection\n",
        "selected_features = ['year', 'Ws', 'FFMC', 'BUI', 'FWI']\n",
        "\n",
        "# Separate features and target\n",
        "X = df[selected_features]\n",
        "y = df[\"Classes\"]\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train1)\n",
        "X_test_scaled = scaler.transform(X_test1)"
      ],
      "metadata": {
        "id": "9nq2OPKVRqq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Feature Selection for the best 6 models"
      ],
      "metadata": {
        "id": "idge224ac2hD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost with Oversampler"
      ],
      "metadata": {
        "id": "WKNC6dlwdDhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train1, y_train1)\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train_enc1 = le.fit_transform(y_train1)\n",
        "y_test_enc1 = le.transform(y_test1)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "grid_xgb = GridSearchCV(xgb, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_xgb.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best params:\", grid_xgb.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_xgb.best_score_)\n",
        "\n",
        "best_xgb1 = grid_xgb.best_estimator_\n",
        "cv_scores = cross_val_score(best_xgb1, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_xgb = best_xgb1.predict(X_test1)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_enc1, y_pred_xgb))\n",
        "\n",
        "f1_fire = f1_score(y_test_enc1, y_pred_xgb, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test1, y_pred_xgb, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntYKR0LXRvpW",
        "outputId": "614fefc4-80a2-4a0e-c9f8-a34e076ad314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}\n",
            "Best CV Accuracy: 0.9719150133671028\n",
            "CV Scores: [0.96618357 0.96135266 0.96601942 0.98058252 0.98543689]\n",
            "Mean CV: 0.9719150133671028\n",
            "Test Accuracy: 0.9302325581395349\n",
            "Overall F1 Score: 0.9313\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.97      0.94      0.95       130\n",
            "        fire       0.83      0.90      0.86        42\n",
            "\n",
            "    accuracy                           0.93       172\n",
            "   macro avg       0.90      0.92      0.91       172\n",
            "weighted avg       0.93      0.93      0.93       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "KEoiEJkhdJWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train1, y_train1)\n",
        "\n",
        "print(\" Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_cat = best_model.predict(X_test1)\n",
        "\n",
        "print(\"\\nAccuracy:\", round(accuracy_score(y_test1, y_pred_cat), 4))\n",
        "f1_fire = f1_score(y_test1, y_pred_cat, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test1, y_pred_cat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1QiGlkQTIaA",
        "outputId": "20a75369-66a6-4165-e7b6-af1e1097432b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            " Best Parameters: {'depth': 8, 'iterations': 400, 'l2_leaf_reg': 3, 'learning_rate': 0.2}\n",
            "\n",
            "Accuracy: 0.9593\n",
            " Overall F1 Score: 0.9591\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       130\n",
            "           1       0.93      0.90      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.95      0.94      0.94       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensample training"
      ],
      "metadata": {
        "id": "EcZNR26gdLyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=3,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(**grid_svm.best_params_, probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# XGBoost doesn’t need scaling\n",
        "xgb_model = XGBClassifier(**grid_xgb.best_params_, random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "# Create the VotingClassifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catBoost', catboost_model),\n",
        "        ('svm', svm_pipeline),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting to benefit from predicted probabilities\n",
        ")\n",
        "\n",
        "# Fit the ensemble\n",
        "voting_clf.fit(X_train1, y_train_enc1)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_ensemble = voting_clf.predict(X_test1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Ensemble Test Accuracy:\", accuracy_score(y_test_enc1, y_pred_ensemble))\n",
        "f1_fire = f1_score(y_test_enc1, y_pred_ensemble, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "print(\"\\nEnsemble Classification Report:\\n\", classification_report(y_test1, y_pred_ensemble, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "firmLMO1UGdq",
        "outputId": "6847fea1-b2b6-480a-f800-15734874ea9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.9593023255813954\n",
            "Overall F1 Score: 0.9591\n",
            "\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.97      0.98      0.97       130\n",
            "        fire       0.93      0.90      0.92        42\n",
            "\n",
            "    accuracy                           0.96       172\n",
            "   macro avg       0.95      0.94      0.94       172\n",
            "weighted avg       0.96      0.96      0.96       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet model"
      ],
      "metadata": {
        "id": "v99m02jJdWPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train1)\n",
        "\n",
        "X_train_np = X_train_scaled.astype(\"float32\")\n",
        "X_test_np = X_test_scaled.astype(\"float32\")\n",
        "y_train_np = y_train.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# Initialize and Train TabNet\n",
        "clf = TabNetClassifier(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=70,\n",
        "    patience=25,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    weights=sample_weights  # fixes the imbalance\n",
        "\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = clf.predict(X_test_np)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_np, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_np, y_pred))\n",
        "\n",
        "# Plot Feature Importances\n",
        "feature_names = X.columns\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"TabNet Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"F1 Score: {f1_score(y_test_np, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qfFbMF98a8lL",
        "outputId": "5e1f99cc-7178-42c9-927a-c861a43279a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.66556 | train_accuracy: 0.69006 | valid_accuracy: 0.69767 |  0:00:00s\n",
            "epoch 1  | loss: 0.52876 | train_accuracy: 0.79386 | valid_accuracy: 0.77326 |  0:00:00s\n",
            "epoch 2  | loss: 0.4504  | train_accuracy: 0.84211 | valid_accuracy: 0.80233 |  0:00:00s\n",
            "epoch 3  | loss: 0.41871 | train_accuracy: 0.85234 | valid_accuracy: 0.80814 |  0:00:00s\n",
            "epoch 4  | loss: 0.39294 | train_accuracy: 0.75292 | valid_accuracy: 0.7093  |  0:00:01s\n",
            "epoch 5  | loss: 0.37079 | train_accuracy: 0.65205 | valid_accuracy: 0.62791 |  0:00:01s\n",
            "epoch 6  | loss: 0.36946 | train_accuracy: 0.76462 | valid_accuracy: 0.75    |  0:00:02s\n",
            "epoch 7  | loss: 0.35063 | train_accuracy: 0.8538  | valid_accuracy: 0.81395 |  0:00:02s\n",
            "epoch 8  | loss: 0.39296 | train_accuracy: 0.83333 | valid_accuracy: 0.84302 |  0:00:02s\n",
            "epoch 9  | loss: 0.36357 | train_accuracy: 0.77778 | valid_accuracy: 0.79651 |  0:00:02s\n",
            "epoch 10 | loss: 0.32534 | train_accuracy: 0.78947 | valid_accuracy: 0.7907  |  0:00:03s\n",
            "epoch 11 | loss: 0.31607 | train_accuracy: 0.80409 | valid_accuracy: 0.8314  |  0:00:03s\n",
            "epoch 12 | loss: 0.38307 | train_accuracy: 0.79971 | valid_accuracy: 0.81395 |  0:00:04s\n",
            "epoch 13 | loss: 0.37393 | train_accuracy: 0.77339 | valid_accuracy: 0.7907  |  0:00:04s\n",
            "epoch 14 | loss: 0.31849 | train_accuracy: 0.8231  | valid_accuracy: 0.82558 |  0:00:04s\n",
            "epoch 15 | loss: 0.33188 | train_accuracy: 0.83626 | valid_accuracy: 0.83721 |  0:00:04s\n",
            "epoch 16 | loss: 0.32514 | train_accuracy: 0.8348  | valid_accuracy: 0.8314  |  0:00:05s\n",
            "epoch 17 | loss: 0.3048  | train_accuracy: 0.83918 | valid_accuracy: 0.84302 |  0:00:05s\n",
            "epoch 18 | loss: 0.3288  | train_accuracy: 0.8538  | valid_accuracy: 0.8314  |  0:00:05s\n",
            "epoch 19 | loss: 0.30537 | train_accuracy: 0.84211 | valid_accuracy: 0.83721 |  0:00:05s\n",
            "epoch 20 | loss: 0.36134 | train_accuracy: 0.79971 | valid_accuracy: 0.80814 |  0:00:06s\n",
            "epoch 21 | loss: 0.31782 | train_accuracy: 0.83187 | valid_accuracy: 0.8314  |  0:00:06s\n",
            "epoch 22 | loss: 0.34641 | train_accuracy: 0.86257 | valid_accuracy: 0.83721 |  0:00:07s\n",
            "epoch 23 | loss: 0.31007 | train_accuracy: 0.87281 | valid_accuracy: 0.8314  |  0:00:07s\n",
            "epoch 24 | loss: 0.30721 | train_accuracy: 0.86842 | valid_accuracy: 0.8314  |  0:00:07s\n",
            "epoch 25 | loss: 0.32836 | train_accuracy: 0.86988 | valid_accuracy: 0.83721 |  0:00:07s\n",
            "epoch 26 | loss: 0.32168 | train_accuracy: 0.87573 | valid_accuracy: 0.83721 |  0:00:08s\n",
            "epoch 27 | loss: 0.30684 | train_accuracy: 0.88596 | valid_accuracy: 0.87209 |  0:00:08s\n",
            "epoch 28 | loss: 0.36245 | train_accuracy: 0.89035 | valid_accuracy: 0.86047 |  0:00:08s\n",
            "epoch 29 | loss: 0.29446 | train_accuracy: 0.88743 | valid_accuracy: 0.84884 |  0:00:09s\n",
            "epoch 30 | loss: 0.30461 | train_accuracy: 0.89327 | valid_accuracy: 0.84884 |  0:00:09s\n",
            "epoch 31 | loss: 0.30141 | train_accuracy: 0.89474 | valid_accuracy: 0.83721 |  0:00:09s\n",
            "epoch 32 | loss: 0.30045 | train_accuracy: 0.89912 | valid_accuracy: 0.84884 |  0:00:10s\n",
            "epoch 33 | loss: 0.30009 | train_accuracy: 0.90351 | valid_accuracy: 0.84302 |  0:00:11s\n",
            "epoch 34 | loss: 0.31911 | train_accuracy: 0.90643 | valid_accuracy: 0.82558 |  0:00:11s\n",
            "epoch 35 | loss: 0.27714 | train_accuracy: 0.86988 | valid_accuracy: 0.82558 |  0:00:12s\n",
            "epoch 36 | loss: 0.30316 | train_accuracy: 0.85819 | valid_accuracy: 0.80814 |  0:00:12s\n",
            "epoch 37 | loss: 0.29286 | train_accuracy: 0.8845  | valid_accuracy: 0.80233 |  0:00:12s\n",
            "epoch 38 | loss: 0.28576 | train_accuracy: 0.89474 | valid_accuracy: 0.8314  |  0:00:13s\n",
            "epoch 39 | loss: 0.26206 | train_accuracy: 0.89327 | valid_accuracy: 0.82558 |  0:00:13s\n",
            "epoch 40 | loss: 0.27819 | train_accuracy: 0.88304 | valid_accuracy: 0.84302 |  0:00:13s\n",
            "epoch 41 | loss: 0.24896 | train_accuracy: 0.87719 | valid_accuracy: 0.8314  |  0:00:13s\n",
            "epoch 42 | loss: 0.28153 | train_accuracy: 0.85965 | valid_accuracy: 0.81395 |  0:00:14s\n",
            "epoch 43 | loss: 0.3234  | train_accuracy: 0.84211 | valid_accuracy: 0.7907  |  0:00:14s\n",
            "epoch 44 | loss: 0.28038 | train_accuracy: 0.86988 | valid_accuracy: 0.81977 |  0:00:14s\n",
            "epoch 45 | loss: 0.30804 | train_accuracy: 0.89327 | valid_accuracy: 0.82558 |  0:00:14s\n",
            "epoch 46 | loss: 0.27566 | train_accuracy: 0.90351 | valid_accuracy: 0.85465 |  0:00:15s\n",
            "epoch 47 | loss: 0.24967 | train_accuracy: 0.90058 | valid_accuracy: 0.84884 |  0:00:15s\n",
            "epoch 48 | loss: 0.26674 | train_accuracy: 0.89327 | valid_accuracy: 0.84302 |  0:00:15s\n",
            "epoch 49 | loss: 0.30509 | train_accuracy: 0.88304 | valid_accuracy: 0.82558 |  0:00:15s\n",
            "epoch 50 | loss: 0.30415 | train_accuracy: 0.87719 | valid_accuracy: 0.81977 |  0:00:15s\n",
            "epoch 51 | loss: 0.26279 | train_accuracy: 0.88889 | valid_accuracy: 0.85465 |  0:00:15s\n",
            "epoch 52 | loss: 0.23426 | train_accuracy: 0.90643 | valid_accuracy: 0.84884 |  0:00:15s\n",
            "\n",
            "Early stopping occurred at epoch 52 with best_epoch = 27 and best_valid_accuracy = 0.87209\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91       130\n",
            "           1       0.69      0.86      0.77        42\n",
            "\n",
            "    accuracy                           0.87       172\n",
            "   macro avg       0.82      0.87      0.84       172\n",
            "weighted avg       0.89      0.87      0.88       172\n",
            "\n",
            "Confusion Matrix:\n",
            " [[114  16]\n",
            " [  6  36]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.8763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "WHdZYxvvda9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape (3D: samples, timesteps, features)\n",
        "X_train_lstm = X_train1.values.reshape((X_train1.shape[0], X_train1.shape[1], 1))\n",
        "X_test_lstm = X_test1.values.reshape((X_test1.shape[0], X_test1.shape[1], 1))\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]),\n",
        "         kernel_regularizer=regularizers.l2(0.001), return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_lstm = model_lstm.fit(\n",
        "    X_train_lstm, y_train_enc1,\n",
        "    validation_data=(X_test_lstm, y_test_enc1),\n",
        "    epochs=70, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "loss, acc = model_lstm.evaluate(X_test_lstm, y_test_enc1, verbose=0)\n",
        "print(\"LSTM Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test_lstm)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc1\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n {cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k1SC-90ZA9s",
        "outputId": "3664bfc2-1301-41e6-8359-9b62f89b3a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7217 - loss: 0.5810 - val_accuracy: 0.7558 - val_loss: 0.5051\n",
            "Epoch 2/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7821 - loss: 0.5040 - val_accuracy: 0.7733 - val_loss: 0.4665\n",
            "Epoch 3/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8211 - loss: 0.4546 - val_accuracy: 0.8605 - val_loss: 0.4566\n",
            "Epoch 4/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.4508 - val_accuracy: 0.8895 - val_loss: 0.4059\n",
            "Epoch 5/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8612 - loss: 0.4170 - val_accuracy: 0.8663 - val_loss: 0.3782\n",
            "Epoch 6/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8816 - loss: 0.3951 - val_accuracy: 0.8779 - val_loss: 0.3606\n",
            "Epoch 7/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8540 - loss: 0.4161 - val_accuracy: 0.8663 - val_loss: 0.3658\n",
            "Epoch 8/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8756 - loss: 0.3540 - val_accuracy: 0.8663 - val_loss: 0.3579\n",
            "Epoch 9/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8829 - loss: 0.3276 - val_accuracy: 0.8663 - val_loss: 0.3598\n",
            "Epoch 10/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8841 - loss: 0.3413 - val_accuracy: 0.8663 - val_loss: 0.3536\n",
            "Epoch 11/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8656 - loss: 0.3824 - val_accuracy: 0.8721 - val_loss: 0.3425\n",
            "Epoch 12/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8804 - loss: 0.3264 - val_accuracy: 0.8837 - val_loss: 0.3368\n",
            "Epoch 13/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8855 - loss: 0.3336 - val_accuracy: 0.8721 - val_loss: 0.3357\n",
            "Epoch 14/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8860 - loss: 0.3180 - val_accuracy: 0.8895 - val_loss: 0.3307\n",
            "Epoch 15/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8865 - loss: 0.3195 - val_accuracy: 0.8721 - val_loss: 0.3436\n",
            "Epoch 16/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8741 - loss: 0.3649 - val_accuracy: 0.8721 - val_loss: 0.3361\n",
            "Epoch 17/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8796 - loss: 0.3412 - val_accuracy: 0.8779 - val_loss: 0.3309\n",
            "Epoch 18/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8968 - loss: 0.3261 - val_accuracy: 0.8779 - val_loss: 0.3330\n",
            "Epoch 19/70\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8787 - loss: 0.3530 - val_accuracy: 0.8837 - val_loss: 0.3345\n",
            "LSTM Test Accuracy: 0.8895348906517029\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            " [[128   2]\n",
            " [ 17  25]]\n",
            "\n",
            "Classification Report:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       130\n",
            "           1       0.93      0.60      0.72        42\n",
            "\n",
            "    accuracy                           0.89       172\n",
            "   macro avg       0.90      0.79      0.83       172\n",
            "weighted avg       0.89      0.89      0.88       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "Q2-tOfUNdcqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN2D: (samples, rows, cols, channels)\n",
        "X_train_cnn2d = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "#buikd the model\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_train_cnn2d, y_train_enc1,\n",
        "    validation_data=(X_test_cnn2d, y_test_enc1),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test_enc1, verbose=0)\n",
        "print(\" CNN2D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc1\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\n F1 Score: {f1_fire:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQJkiPfdZhAH",
        "outputId": "0c87fba0-04d7-41a1-b437-2b88e2e3a354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.6624 - loss: 0.7446 - val_accuracy: 0.7558 - val_loss: 0.6239\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7531 - loss: 0.6457 - val_accuracy: 0.7558 - val_loss: 0.5560\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7792 - loss: 0.6018 - val_accuracy: 0.8372 - val_loss: 0.4997\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8355 - loss: 0.5294 - val_accuracy: 0.8779 - val_loss: 0.4720\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8082 - loss: 0.5376 - val_accuracy: 0.8779 - val_loss: 0.4430\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8644 - loss: 0.4796 - val_accuracy: 0.8895 - val_loss: 0.4348\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8416 - loss: 0.4691 - val_accuracy: 0.8895 - val_loss: 0.4286\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8617 - loss: 0.4461 - val_accuracy: 0.8895 - val_loss: 0.4204\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8498 - loss: 0.4977 - val_accuracy: 0.8953 - val_loss: 0.4178\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8495 - loss: 0.4648 - val_accuracy: 0.9012 - val_loss: 0.4145\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8258 - loss: 0.4981 - val_accuracy: 0.8953 - val_loss: 0.4112\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8747 - loss: 0.4356 - val_accuracy: 0.8953 - val_loss: 0.4059\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8595 - loss: 0.4496 - val_accuracy: 0.8953 - val_loss: 0.3994\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8765 - loss: 0.4407 - val_accuracy: 0.9012 - val_loss: 0.3987\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8875 - loss: 0.4141 - val_accuracy: 0.8953 - val_loss: 0.3957\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8625 - loss: 0.4407 - val_accuracy: 0.9012 - val_loss: 0.3904\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8800 - loss: 0.4147 - val_accuracy: 0.9012 - val_loss: 0.3849\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8584 - loss: 0.4285 - val_accuracy: 0.9012 - val_loss: 0.3857\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.3703 - val_accuracy: 0.8953 - val_loss: 0.3851\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8789 - loss: 0.4063 - val_accuracy: 0.9012 - val_loss: 0.3766\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8744 - loss: 0.4147 - val_accuracy: 0.9012 - val_loss: 0.3715\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8686 - loss: 0.3804 - val_accuracy: 0.9070 - val_loss: 0.3733\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8768 - loss: 0.4052 - val_accuracy: 0.9070 - val_loss: 0.3690\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8837 - loss: 0.3948 - val_accuracy: 0.9012 - val_loss: 0.3602\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8712 - loss: 0.4256 - val_accuracy: 0.9012 - val_loss: 0.3645\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8942 - loss: 0.3583 - val_accuracy: 0.9012 - val_loss: 0.3610\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8852 - loss: 0.3747 - val_accuracy: 0.9070 - val_loss: 0.3571\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8837 - loss: 0.3997 - val_accuracy: 0.9070 - val_loss: 0.3643\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8928 - loss: 0.3620 - val_accuracy: 0.9012 - val_loss: 0.3500\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9063 - loss: 0.3490 - val_accuracy: 0.9012 - val_loss: 0.3552\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8944 - loss: 0.3691 - val_accuracy: 0.9070 - val_loss: 0.3416\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8965 - loss: 0.3823 - val_accuracy: 0.9012 - val_loss: 0.3492\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8863 - loss: 0.3624 - val_accuracy: 0.8895 - val_loss: 0.3506\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8601 - loss: 0.4173 - val_accuracy: 0.9070 - val_loss: 0.3444\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8982 - loss: 0.3703 - val_accuracy: 0.8953 - val_loss: 0.3461\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9032 - loss: 0.3613 - val_accuracy: 0.9070 - val_loss: 0.3413\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8910 - loss: 0.3640 - val_accuracy: 0.8953 - val_loss: 0.3376\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8809 - loss: 0.3771 - val_accuracy: 0.9070 - val_loss: 0.3293\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.3535 - val_accuracy: 0.9070 - val_loss: 0.3319\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8861 - loss: 0.3903 - val_accuracy: 0.9070 - val_loss: 0.3263\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8918 - loss: 0.3499 - val_accuracy: 0.8953 - val_loss: 0.3356\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8922 - loss: 0.3521 - val_accuracy: 0.8953 - val_loss: 0.3439\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8882 - loss: 0.3588 - val_accuracy: 0.9070 - val_loss: 0.3335\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8991 - loss: 0.3480 - val_accuracy: 0.9070 - val_loss: 0.3404\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8943 - loss: 0.3778 - val_accuracy: 0.9070 - val_loss: 0.3323\n",
            " CNN2D Test Accuracy: 0.9069767594337463\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[128   2]\n",
            " [ 14  28]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       130\n",
            "           1       0.93      0.67      0.78        42\n",
            "\n",
            "    accuracy                           0.91       172\n",
            "   macro avg       0.92      0.83      0.86       172\n",
            "weighted avg       0.91      0.91      0.90       172\n",
            "\n",
            "\n",
            " F1 Score: 0.9013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RFECV"
      ],
      "metadata": {
        "id": "7-u9tPH6zV1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df_RFECV = pd.read_csv(\"/content/merged_fire_data_cleaned.csv\")\n",
        "\n",
        "X = df_RFECV.drop(\"Classes\", axis=1)\n",
        "y = df_RFECV[\"Classes\"]\n",
        "\n",
        "# splite data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# RFECV with XGboost\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rfecv = RFECV(\n",
        "    estimator=XGBClassifier(random_state=42, n_estimators=300, learning_rate=0.1),\n",
        "    step=1,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rfecv.fit(X_train_scaled, y_train)\n",
        "\n",
        "#Extract selected features\n",
        "\n",
        "selected_features = X.columns[rfecv.support_]\n",
        "\n",
        "print(\"RFECV RESULTS\")\n",
        "print(\"Selected Features:\", selected_features.tolist())\n",
        "print(\"Number of Features:\", rfecv.n_features_)\n"
      ],
      "metadata": {
        "id": "9pusTXkUzccD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ef56e6-279c-4935-c327-1165d25edf05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFECV RESULTS\n",
            "Selected Features: ['day', 'month', 'year', 'Temperature', 'Ws', 'Rain', 'FFMC', 'DC', 'ISI', 'BUI']\n",
            "Number of Features: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2 = X_train[selected_features]\n",
        "X_test2 = X_test[selected_features]\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "X_train2_scaled = scaler2.fit_transform(X_train2)\n",
        "X_test2_scaled = scaler2.transform(X_test2)"
      ],
      "metadata": {
        "id": "e-7ZElLq78Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Feature Selection for the best 6 models"
      ],
      "metadata": {
        "id": "DhOZ2t5B8QXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost with Oversampler"
      ],
      "metadata": {
        "id": "F1tMFVbl8Q6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train2, y_train)\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train_enc2 = le.fit_transform(y_train)\n",
        "y_test_enc2 = le.transform(y_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "grid_xgb = GridSearchCV(xgb, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_xgb.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Best params:\", grid_xgb.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_xgb.best_score_)\n",
        "\n",
        "best_xgb1 = grid_xgb.best_estimator_\n",
        "cv_scores = cross_val_score(best_xgb1, X_train_res, y_train_res, cv=5, scoring=\"accuracy\")\n",
        "print(\"CV Scores:\", cv_scores)\n",
        "print(\"Mean CV:\", cv_scores.mean())\n",
        "\n",
        "y_pred_xgb = best_xgb1.predict(X_test2)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test_enc2, y_pred_xgb))\n",
        "\n",
        "f1_fire = f1_score(y_test_enc2, y_pred_xgb, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xejNIh-A8Oy_",
        "outputId": "3d171b6d-6844-485f-d86c-8eac73a241ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
            "Best CV Accuracy: 0.9796444819661367\n",
            "CV Scores: [0.98067633 0.98550725 0.97572816 0.97572816 0.98058252]\n",
            "Mean CV: 0.9796444819661367\n",
            "Test Accuracy: 0.9418604651162791\n",
            "Overall F1 Score: 0.9427\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.98      0.95      0.96       130\n",
            "        fire       0.85      0.93      0.89        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.91      0.94      0.92       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "catboost"
      ],
      "metadata": {
        "id": "I9Sc9RYHOpCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train2, y_train)\n",
        "\n",
        "print(\" Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_cat = best_model.predict(X_test2)\n",
        "\n",
        "print(\"\\nAccuracy:\", round(accuracy_score(y_test, y_pred_cat), 4))\n",
        "f1_fire = f1_score(y_test, y_pred_cat, average='weighted')\n",
        "print(f\" Overall F1 Score: {f1_fire:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cat))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eX_om5RPvft",
        "outputId": "a76792ef-559f-4d2b-ad25-8c5e8e31fae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            " Best Parameters: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 5, 'learning_rate': 0.2}\n",
            "\n",
            "Accuracy: 0.9477\n",
            " Overall F1 Score: 0.9479\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       130\n",
            "           1       0.88      0.90      0.89        42\n",
            "\n",
            "    accuracy                           0.95       172\n",
            "   macro avg       0.93      0.93      0.93       172\n",
            "weighted avg       0.95      0.95      0.95       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensample training"
      ],
      "metadata": {
        "id": "0TMK19-4QKnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    iterations=400,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=3,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(**grid_svm.best_params_, probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# XGBoost doesn’t need scaling\n",
        "xgb_model = XGBClassifier(**grid_xgb.best_params_, random_state=42, eval_metric='mlogloss')\n",
        "\n",
        "# Create the VotingClassifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('catBoost', catboost_model),\n",
        "        ('svm', svm_pipeline),\n",
        "        ('xgb', xgb_model)\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting to benefit from predicted probabilities\n",
        ")\n",
        "\n",
        "# Fit the ensemble\n",
        "voting_clf.fit(X_train2, y_train_enc2)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_ensemble = voting_clf.predict(X_test2)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Ensemble Test Accuracy:\", accuracy_score(y_test_enc2, y_pred_ensemble))\n",
        "f1_fire = f1_score(y_test_enc2, y_pred_ensemble, average='weighted')\n",
        "print(f\"Overall F1 Score: {f1_fire:.4f}\")\n",
        "\n",
        "print(\"\\nEnsemble Classification Report:\\n\", classification_report(y_test, y_pred_ensemble, target_names=[\"not fire\", \"fire\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EhN8VJZQLU_",
        "outputId": "fa4ab930-a8fe-4d8e-95eb-0424d9ebb1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.9534883720930233\n",
            "Overall F1 Score: 0.9535\n",
            "\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    not fire       0.97      0.97      0.97       130\n",
            "        fire       0.90      0.90      0.90        42\n",
            "\n",
            "    accuracy                           0.95       172\n",
            "   macro avg       0.94      0.94      0.94       172\n",
            "weighted avg       0.95      0.95      0.95       172\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TabNet model"
      ],
      "metadata": {
        "id": "KEahC9zfQzci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "\n",
        "X_train_np = X_train_scaled.astype(\"float32\")\n",
        "X_test_np = X_test_scaled.astype(\"float32\")\n",
        "y_train_np = y_train.values\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# Initialize and Train TabNet\n",
        "clf = TabNetClassifier(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    verbose=1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train_np, y_train=y_train_np,\n",
        "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=70,\n",
        "    patience=25,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    weights=sample_weights  # fixes the imbalance\n",
        "\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = clf.predict(X_test_np)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_np, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_np, y_pred))\n",
        "\n",
        "# Plot Feature Importances\n",
        "feature_names = X.columns\n",
        "importances = clf.feature_importances_\n",
        "importances = importances[:len(feature_names)]  # keep only real feature importances\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, importances)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"TabNet Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"F1 Score: {f1_score(y_test_np, y_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A56SR5sgQ8rG",
        "outputId": "c89cf4b7-b24d-4f53-ae09-e048cabfe25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.96959 | train_accuracy: 0.51462 | valid_accuracy: 0.50581 |  0:00:00s\n",
            "epoch 1  | loss: 0.66358 | train_accuracy: 0.59211 | valid_accuracy: 0.62209 |  0:00:00s\n",
            "epoch 2  | loss: 0.60881 | train_accuracy: 0.66959 | valid_accuracy: 0.6686  |  0:00:00s\n",
            "epoch 3  | loss: 0.5881  | train_accuracy: 0.72953 | valid_accuracy: 0.68605 |  0:00:00s\n",
            "epoch 4  | loss: 0.52717 | train_accuracy: 0.72222 | valid_accuracy: 0.7093  |  0:00:00s\n",
            "epoch 5  | loss: 0.49413 | train_accuracy: 0.72368 | valid_accuracy: 0.68605 |  0:00:00s\n",
            "epoch 6  | loss: 0.50074 | train_accuracy: 0.74708 | valid_accuracy: 0.72674 |  0:00:00s\n",
            "epoch 7  | loss: 0.47484 | train_accuracy: 0.77047 | valid_accuracy: 0.75    |  0:00:01s\n",
            "epoch 8  | loss: 0.43292 | train_accuracy: 0.78801 | valid_accuracy: 0.76163 |  0:00:01s\n",
            "epoch 9  | loss: 0.40556 | train_accuracy: 0.84064 | valid_accuracy: 0.82558 |  0:00:01s\n",
            "epoch 10 | loss: 0.41802 | train_accuracy: 0.83626 | valid_accuracy: 0.82558 |  0:00:01s\n",
            "epoch 11 | loss: 0.3896  | train_accuracy: 0.79386 | valid_accuracy: 0.76163 |  0:00:01s\n",
            "epoch 12 | loss: 0.39007 | train_accuracy: 0.79971 | valid_accuracy: 0.74419 |  0:00:01s\n",
            "epoch 13 | loss: 0.35683 | train_accuracy: 0.81871 | valid_accuracy: 0.77907 |  0:00:01s\n",
            "epoch 14 | loss: 0.42237 | train_accuracy: 0.83041 | valid_accuracy: 0.78488 |  0:00:01s\n",
            "epoch 15 | loss: 0.38807 | train_accuracy: 0.86257 | valid_accuracy: 0.79651 |  0:00:02s\n",
            "epoch 16 | loss: 0.36869 | train_accuracy: 0.88158 | valid_accuracy: 0.80814 |  0:00:02s\n",
            "epoch 17 | loss: 0.37814 | train_accuracy: 0.89766 | valid_accuracy: 0.86047 |  0:00:02s\n",
            "epoch 18 | loss: 0.33609 | train_accuracy: 0.89912 | valid_accuracy: 0.88372 |  0:00:02s\n",
            "epoch 19 | loss: 0.3646  | train_accuracy: 0.91082 | valid_accuracy: 0.88953 |  0:00:02s\n",
            "epoch 20 | loss: 0.34284 | train_accuracy: 0.91667 | valid_accuracy: 0.88953 |  0:00:02s\n",
            "epoch 21 | loss: 0.40296 | train_accuracy: 0.9152  | valid_accuracy: 0.87791 |  0:00:02s\n",
            "epoch 22 | loss: 0.35073 | train_accuracy: 0.90789 | valid_accuracy: 0.89535 |  0:00:03s\n",
            "epoch 23 | loss: 0.33312 | train_accuracy: 0.90351 | valid_accuracy: 0.87791 |  0:00:03s\n",
            "epoch 24 | loss: 0.35047 | train_accuracy: 0.89035 | valid_accuracy: 0.87791 |  0:00:03s\n",
            "epoch 25 | loss: 0.37448 | train_accuracy: 0.8962  | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 26 | loss: 0.36435 | train_accuracy: 0.89766 | valid_accuracy: 0.93023 |  0:00:03s\n",
            "epoch 27 | loss: 0.3636  | train_accuracy: 0.8538  | valid_accuracy: 0.90698 |  0:00:03s\n",
            "epoch 28 | loss: 0.30962 | train_accuracy: 0.88158 | valid_accuracy: 0.91279 |  0:00:03s\n",
            "epoch 29 | loss: 0.3402  | train_accuracy: 0.90497 | valid_accuracy: 0.9186  |  0:00:03s\n",
            "epoch 30 | loss: 0.33953 | train_accuracy: 0.91667 | valid_accuracy: 0.92442 |  0:00:04s\n",
            "epoch 31 | loss: 0.31677 | train_accuracy: 0.91959 | valid_accuracy: 0.89535 |  0:00:04s\n",
            "epoch 32 | loss: 0.30843 | train_accuracy: 0.92105 | valid_accuracy: 0.90698 |  0:00:04s\n",
            "epoch 33 | loss: 0.29902 | train_accuracy: 0.91228 | valid_accuracy: 0.93605 |  0:00:04s\n",
            "epoch 34 | loss: 0.30287 | train_accuracy: 0.91667 | valid_accuracy: 0.92442 |  0:00:04s\n",
            "epoch 35 | loss: 0.29169 | train_accuracy: 0.91667 | valid_accuracy: 0.9186  |  0:00:04s\n",
            "epoch 36 | loss: 0.33445 | train_accuracy: 0.90789 | valid_accuracy: 0.89535 |  0:00:04s\n",
            "epoch 37 | loss: 0.26482 | train_accuracy: 0.91228 | valid_accuracy: 0.91279 |  0:00:04s\n",
            "epoch 38 | loss: 0.31379 | train_accuracy: 0.9152  | valid_accuracy: 0.90116 |  0:00:05s\n",
            "epoch 39 | loss: 0.2863  | train_accuracy: 0.91813 | valid_accuracy: 0.93023 |  0:00:05s\n",
            "epoch 40 | loss: 0.28941 | train_accuracy: 0.90789 | valid_accuracy: 0.93023 |  0:00:05s\n",
            "epoch 41 | loss: 0.32044 | train_accuracy: 0.86404 | valid_accuracy: 0.87209 |  0:00:05s\n",
            "epoch 42 | loss: 0.31874 | train_accuracy: 0.84649 | valid_accuracy: 0.8314  |  0:00:05s\n",
            "epoch 43 | loss: 0.33777 | train_accuracy: 0.86696 | valid_accuracy: 0.84884 |  0:00:05s\n",
            "epoch 44 | loss: 0.33029 | train_accuracy: 0.88012 | valid_accuracy: 0.85465 |  0:00:05s\n",
            "epoch 45 | loss: 0.26574 | train_accuracy: 0.8845  | valid_accuracy: 0.88953 |  0:00:05s\n",
            "epoch 46 | loss: 0.28199 | train_accuracy: 0.8962  | valid_accuracy: 0.90698 |  0:00:06s\n",
            "epoch 47 | loss: 0.25117 | train_accuracy: 0.90789 | valid_accuracy: 0.88953 |  0:00:06s\n",
            "epoch 48 | loss: 0.31125 | train_accuracy: 0.89181 | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 49 | loss: 0.28388 | train_accuracy: 0.8845  | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 50 | loss: 0.245   | train_accuracy: 0.89035 | valid_accuracy: 0.89535 |  0:00:06s\n",
            "epoch 51 | loss: 0.24625 | train_accuracy: 0.8962  | valid_accuracy: 0.89535 |  0:00:06s\n",
            "epoch 52 | loss: 0.25757 | train_accuracy: 0.90789 | valid_accuracy: 0.87791 |  0:00:06s\n",
            "epoch 53 | loss: 0.26351 | train_accuracy: 0.90497 | valid_accuracy: 0.88372 |  0:00:06s\n",
            "epoch 54 | loss: 0.26658 | train_accuracy: 0.89035 | valid_accuracy: 0.88372 |  0:00:07s\n",
            "epoch 55 | loss: 0.24475 | train_accuracy: 0.89327 | valid_accuracy: 0.88953 |  0:00:07s\n",
            "epoch 56 | loss: 0.25243 | train_accuracy: 0.88596 | valid_accuracy: 0.87209 |  0:00:07s\n",
            "epoch 57 | loss: 0.24037 | train_accuracy: 0.87281 | valid_accuracy: 0.86628 |  0:00:07s\n",
            "epoch 58 | loss: 0.26313 | train_accuracy: 0.87865 | valid_accuracy: 0.85465 |  0:00:07s\n",
            "\n",
            "Early stopping occurred at epoch 58 with best_epoch = 33 and best_valid_accuracy = 0.93605\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96       130\n",
            "           1       0.88      0.86      0.87        42\n",
            "\n",
            "    accuracy                           0.94       172\n",
            "   macro avg       0.92      0.91      0.91       172\n",
            "weighted avg       0.94      0.94      0.94       172\n",
            "\n",
            "Confusion Matrix:\n",
            " [[125   5]\n",
            " [  6  36]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "heb3IW6wRI5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape (3D: samples, timesteps, features)\n",
        "X_train_lstm = X_train2.values.reshape((X_train2.shape[0], X_train2.shape[1], 1))\n",
        "X_test_lstm = X_test2.values.reshape((X_test2.shape[0], X_test2.shape[1], 1))\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]),\n",
        "         kernel_regularizer=regularizers.l2(0.001), return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
        "\n",
        "history_lstm = model_lstm.fit(\n",
        "    X_train_lstm, y_train_enc2,\n",
        "    validation_data=(X_test_lstm, y_test_enc2),\n",
        "    epochs=50, batch_size=16, verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "loss, acc = model_lstm.evaluate(X_test_lstm, y_test_enc2, verbose=0)\n",
        "print(\"LSTM Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_lstm.predict(X_test_lstm)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc2\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n {cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\nF1 Score: {f1_fire:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYCbr05RZbU",
        "outputId": "c38be460-d1d7-4bdf-b828-0c19f449518f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7142 - loss: 0.6003 - val_accuracy: 0.7558 - val_loss: 0.4856\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.5316 - val_accuracy: 0.8081 - val_loss: 0.4318\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8029 - loss: 0.4394 - val_accuracy: 0.8779 - val_loss: 0.3962\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8599 - loss: 0.4145 - val_accuracy: 0.8663 - val_loss: 0.3826\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8598 - loss: 0.3930 - val_accuracy: 0.8721 - val_loss: 0.3815\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8318 - loss: 0.4486 - val_accuracy: 0.8721 - val_loss: 0.3706\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8594 - loss: 0.3719 - val_accuracy: 0.8721 - val_loss: 0.3784\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8665 - loss: 0.3655 - val_accuracy: 0.8663 - val_loss: 0.3740\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8532 - loss: 0.3972 - val_accuracy: 0.8663 - val_loss: 0.3627\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8371 - loss: 0.4234 - val_accuracy: 0.8721 - val_loss: 0.3693\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8627 - loss: 0.3774 - val_accuracy: 0.8663 - val_loss: 0.3626\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8506 - loss: 0.4026 - val_accuracy: 0.8663 - val_loss: 0.3563\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8862 - loss: 0.3463 - val_accuracy: 0.8663 - val_loss: 0.3577\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8880 - loss: 0.3337 - val_accuracy: 0.8663 - val_loss: 0.3537\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8643 - loss: 0.3891 - val_accuracy: 0.8721 - val_loss: 0.3600\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8706 - loss: 0.3555 - val_accuracy: 0.8779 - val_loss: 0.3518\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8725 - loss: 0.3632 - val_accuracy: 0.8779 - val_loss: 0.3483\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8395 - loss: 0.4053 - val_accuracy: 0.8779 - val_loss: 0.3486\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8708 - loss: 0.3469 - val_accuracy: 0.8779 - val_loss: 0.3457\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8601 - loss: 0.3724 - val_accuracy: 0.8663 - val_loss: 0.3592\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8861 - loss: 0.3333 - val_accuracy: 0.8779 - val_loss: 0.3459\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8808 - loss: 0.3537 - val_accuracy: 0.8663 - val_loss: 0.3516\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8728 - loss: 0.3634 - val_accuracy: 0.8779 - val_loss: 0.3411\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8597 - loss: 0.3581 - val_accuracy: 0.8721 - val_loss: 0.3441\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8787 - loss: 0.3558 - val_accuracy: 0.8779 - val_loss: 0.3379\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8604 - loss: 0.3756 - val_accuracy: 0.8837 - val_loss: 0.3361\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8660 - loss: 0.3591 - val_accuracy: 0.8895 - val_loss: 0.3329\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8766 - loss: 0.3611 - val_accuracy: 0.8779 - val_loss: 0.3376\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8698 - loss: 0.3529 - val_accuracy: 0.8721 - val_loss: 0.3415\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8767 - loss: 0.3353 - val_accuracy: 0.8779 - val_loss: 0.3360\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8864 - loss: 0.3392 - val_accuracy: 0.8837 - val_loss: 0.3286\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8757 - loss: 0.3351 - val_accuracy: 0.8895 - val_loss: 0.3304\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8675 - loss: 0.3656 - val_accuracy: 0.8721 - val_loss: 0.3340\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8992 - loss: 0.2987 - val_accuracy: 0.8895 - val_loss: 0.3200\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8887 - loss: 0.3404 - val_accuracy: 0.8663 - val_loss: 0.3467\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9128 - loss: 0.2881 - val_accuracy: 0.8663 - val_loss: 0.3454\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8733 - loss: 0.3693 - val_accuracy: 0.8895 - val_loss: 0.3172\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8972 - loss: 0.2878 - val_accuracy: 0.8779 - val_loss: 0.3283\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9092 - loss: 0.2998 - val_accuracy: 0.8895 - val_loss: 0.3170\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8869 - loss: 0.3228 - val_accuracy: 0.8837 - val_loss: 0.3228\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8722 - loss: 0.3313 - val_accuracy: 0.8779 - val_loss: 0.3207\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8865 - loss: 0.3254 - val_accuracy: 0.8779 - val_loss: 0.3176\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8920 - loss: 0.3136 - val_accuracy: 0.8837 - val_loss: 0.3145\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8805 - loss: 0.3282 - val_accuracy: 0.8837 - val_loss: 0.3100\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8868 - loss: 0.3144 - val_accuracy: 0.8779 - val_loss: 0.3140\n",
            "Epoch 46/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8838 - loss: 0.3342 - val_accuracy: 0.8895 - val_loss: 0.3093\n",
            "Epoch 47/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8980 - loss: 0.2979 - val_accuracy: 0.8953 - val_loss: 0.3047\n",
            "Epoch 48/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8814 - loss: 0.3366 - val_accuracy: 0.9012 - val_loss: 0.3037\n",
            "Epoch 49/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9167 - loss: 0.2625 - val_accuracy: 0.8837 - val_loss: 0.3273\n",
            "Epoch 50/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8947 - loss: 0.3169 - val_accuracy: 0.8895 - val_loss: 0.3146\n",
            "LSTM Test Accuracy: 0.9011628031730652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a17b0084360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            " [[129   1]\n",
            " [ 16  26]]\n",
            "\n",
            "Classification Report:              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94       130\n",
            "           1       0.96      0.62      0.75        42\n",
            "\n",
            "    accuracy                           0.90       172\n",
            "   macro avg       0.93      0.81      0.85       172\n",
            "weighted avg       0.91      0.90      0.89       172\n",
            "\n",
            "\n",
            "F1 Score: 0.8931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN2D"
      ],
      "metadata": {
        "id": "Q2Yt1biLRqyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN2D: (samples, rows, cols, channels)\n",
        "X_train_cnn2d = X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1, 1)\n",
        "X_test_cnn2d = X_test_scaled.reshape(-1, X_test_scaled.shape[1], 1, 1)\n",
        "\n",
        "#buikd the model\n",
        "model_cnn2d = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001),\n",
        "           input_shape=(X_train_cnn2d.shape[1], X_train_cnn2d.shape[2], 1)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(filters=64, kernel_size=(3,1), activation='relu',\n",
        "           kernel_regularizer=regularizers.l2(0.001)),\n",
        "    MaxPooling2D(pool_size=(2,1)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_cnn2d.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "history_cnn2d = model_cnn2d.fit(\n",
        "    X_train_cnn2d, y_train_enc2,\n",
        "    validation_data=(X_test_cnn2d, y_test_enc2),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, acc = model_cnn2d.evaluate(X_test_cnn2d, y_test_enc2, verbose=0)\n",
        "print(\" CNN2D Test Accuracy:\", acc)\n",
        "\n",
        "y_pred_probs = model_cnn2d.predict(X_test_cnn2d)\n",
        "y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "y_true_classes = y_test_enc2\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report:\\n{classification_report(y_true_classes, y_pred_classes)}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_fire = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"\\n F1 Score: {f1_fire:.4f}\")"
      ],
      "metadata": {
        "id": "FHCtrYBcRzzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ed8c95-9798-45bc-b64d-fbdac04420e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6617 - loss: 0.7586 - val_accuracy: 0.7558 - val_loss: 0.6247\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7599 - loss: 0.6463 - val_accuracy: 0.8023 - val_loss: 0.5384\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.5788 - val_accuracy: 0.8663 - val_loss: 0.4886\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.5054 - val_accuracy: 0.9012 - val_loss: 0.4527\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.4909 - val_accuracy: 0.9012 - val_loss: 0.4420\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8616 - loss: 0.4709 - val_accuracy: 0.8953 - val_loss: 0.4351\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8603 - loss: 0.4526 - val_accuracy: 0.8953 - val_loss: 0.4205\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.4732 - val_accuracy: 0.8953 - val_loss: 0.4158\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.4579 - val_accuracy: 0.9012 - val_loss: 0.4123\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.4757 - val_accuracy: 0.9012 - val_loss: 0.4052\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 0.4633 - val_accuracy: 0.9012 - val_loss: 0.3995\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8743 - loss: 0.4369 - val_accuracy: 0.9070 - val_loss: 0.3962\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8705 - loss: 0.4157 - val_accuracy: 0.9070 - val_loss: 0.3923\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8549 - loss: 0.4449 - val_accuracy: 0.9070 - val_loss: 0.3906\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.4165 - val_accuracy: 0.9012 - val_loss: 0.3850\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8767 - loss: 0.4114 - val_accuracy: 0.9012 - val_loss: 0.3771\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.4032 - val_accuracy: 0.9070 - val_loss: 0.3816\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.4491 - val_accuracy: 0.9012 - val_loss: 0.3761\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8934 - loss: 0.4065 - val_accuracy: 0.9070 - val_loss: 0.3767\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.4075 - val_accuracy: 0.9070 - val_loss: 0.3737\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.3957 - val_accuracy: 0.9012 - val_loss: 0.3736\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.3994 - val_accuracy: 0.9070 - val_loss: 0.3723\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.4102 - val_accuracy: 0.9070 - val_loss: 0.3674\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3724 - val_accuracy: 0.9070 - val_loss: 0.3648\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8839 - loss: 0.3740 - val_accuracy: 0.9070 - val_loss: 0.3608\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.3725 - val_accuracy: 0.9070 - val_loss: 0.3598\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8813 - loss: 0.3917 - val_accuracy: 0.9070 - val_loss: 0.3610\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9008 - loss: 0.3606 - val_accuracy: 0.9070 - val_loss: 0.3576\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8825 - loss: 0.3979 - val_accuracy: 0.9070 - val_loss: 0.3569\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8958 - loss: 0.3742 - val_accuracy: 0.9070 - val_loss: 0.3614\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.3574 - val_accuracy: 0.9012 - val_loss: 0.3627\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.3625 - val_accuracy: 0.9070 - val_loss: 0.3541\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.3570 - val_accuracy: 0.9012 - val_loss: 0.3602\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8780 - loss: 0.3856 - val_accuracy: 0.9070 - val_loss: 0.3407\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.3763 - val_accuracy: 0.9070 - val_loss: 0.3420\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9083 - loss: 0.3232 - val_accuracy: 0.9070 - val_loss: 0.3381\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.4144 - val_accuracy: 0.9070 - val_loss: 0.3363\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8727 - loss: 0.3562 - val_accuracy: 0.9070 - val_loss: 0.3299\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8729 - loss: 0.3995 - val_accuracy: 0.9070 - val_loss: 0.3311\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.3424 - val_accuracy: 0.8953 - val_loss: 0.3442\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8654 - loss: 0.4109 - val_accuracy: 0.9070 - val_loss: 0.3273\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.4012 - val_accuracy: 0.9070 - val_loss: 0.3331\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3800 - val_accuracy: 0.9070 - val_loss: 0.3324\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8870 - loss: 0.3513 - val_accuracy: 0.8895 - val_loss: 0.3475\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.3768 - val_accuracy: 0.9070 - val_loss: 0.3409\n",
            "Epoch 46/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - loss: 0.3577 - val_accuracy: 0.9070 - val_loss: 0.3350\n",
            " CNN2D Test Accuracy: 0.9069767594337463\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[128   2]\n",
            " [ 14  28]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       130\n",
            "           1       0.93      0.67      0.78        42\n",
            "\n",
            "    accuracy                           0.91       172\n",
            "   macro avg       0.92      0.83      0.86       172\n",
            "weighted avg       0.91      0.91      0.90       172\n",
            "\n",
            "\n",
            " F1 Score: 0.9013\n"
          ]
        }
      ]
    }
  ]
}